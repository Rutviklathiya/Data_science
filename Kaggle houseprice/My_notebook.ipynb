{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "                ... \n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "SalePrice          0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['MiscFeature','PoolQC','Fence','Alley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 77 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(39)\n",
      "memory usage: 878.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 77)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff0289d6e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 75)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBrkr    1334\n",
       "FuseA      94\n",
       "FuseF      27\n",
       "FuseP       3\n",
       "Mix         1\n",
       "Name: Electrical, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Electrical'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical']=df['Electrical'].fillna(df['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType1']=df['BsmtFinType1'].fillna(df['BsmtFinType1'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BsmtFinType1'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rutvik/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 75)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 236)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0             3       706.0         0.0   \n",
       "1      1262         0          0             3       978.0         0.0   \n",
       "2       920       866          0             3       486.0         0.0   \n",
       "3       961       756          0             3       216.0         0.0   \n",
       "4      1145      1053          0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  Typ  \\\n",
       "0           1.0           0.0      150.0              0  ...     0     0    1   \n",
       "1           0.0           1.0      284.0              0  ...     0     0    1   \n",
       "2           1.0           0.0      434.0              0  ...     0     0    1   \n",
       "3           1.0           0.0      540.0            272  ...     0     0    1   \n",
       "4           1.0           0.0      490.0              0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1422</td>\n",
       "      <td>848</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>686.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1423</td>\n",
       "      <td>1575</td>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424</td>\n",
       "      <td>1344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>457.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>1252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1426</td>\n",
       "      <td>1223</td>\n",
       "      <td>904</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "1422       848         0          0             1       686.0         0.0   \n",
       "1423      1575       626          0             4         0.0         0.0   \n",
       "1424      1344         0          0             2       457.0       374.0   \n",
       "1425      1252         0          0             3         0.0         0.0   \n",
       "1426      1223       904          0             3      1000.0         0.0   \n",
       "\n",
       "      BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  \\\n",
       "1422           1.0           0.0      162.0              0  ...     0     0   \n",
       "1423           0.0           0.0      697.0              0  ...     0     0   \n",
       "1424           1.0           0.0      193.0              0  ...     1     0   \n",
       "1425           0.0           0.0     1252.0              0  ...     0     0   \n",
       "1426           1.0           0.0      223.0              0  ...     0     0   \n",
       "\n",
       "      Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "1422    1       1        0        0        0       0    0  0  \n",
       "1423    1       1        0        0        0       0    0  0  \n",
       "1424    0       0        0        0        0       1    0  0  \n",
       "1425    1       0        0        0        0       1    0  0  \n",
       "1426    1       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rutvik/.local/lib/python3.6/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1497, 175)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rutvik/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=175, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=40, kernel_initializer=\"he_uniform\")`\n",
      "  \n",
      "/home/rutvik/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=30, kernel_initializer=\"he_uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=20, kernel_initializer=\"he_uniform\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/rutvik/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n",
      "/home/rutvik/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1137 samples, validate on 285 samples\n",
      "Epoch 1/1200\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 142492.1654 - acc: 0.0000e+00 - val_loss: 68490.7058 - val_acc: 0.0000e+00\n",
      "Epoch 2/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 71446.0430 - acc: 0.0000e+00 - val_loss: 63957.0970 - val_acc: 0.0000e+00\n",
      "Epoch 3/1200\n",
      "1137/1137 [==============================] - 0s 168us/step - loss: 64899.5502 - acc: 0.0000e+00 - val_loss: 60716.3825 - val_acc: 0.0000e+00\n",
      "Epoch 4/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 61622.6389 - acc: 0.0000e+00 - val_loss: 58500.5430 - val_acc: 0.0000e+00\n",
      "Epoch 5/1200\n",
      "1137/1137 [==============================] - 0s 325us/step - loss: 57723.8143 - acc: 0.0000e+00 - val_loss: 55498.5374 - val_acc: 0.0000e+00\n",
      "Epoch 6/1200\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 54135.9970 - acc: 0.0000e+00 - val_loss: 54028.2436 - val_acc: 0.0000e+00\n",
      "Epoch 7/1200\n",
      "1137/1137 [==============================] - 0s 180us/step - loss: 50275.4757 - acc: 0.0000e+00 - val_loss: 51518.3070 - val_acc: 0.0000e+00\n",
      "Epoch 8/1200\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 48130.5976 - acc: 0.0000e+00 - val_loss: 49736.7938 - val_acc: 0.0000e+00\n",
      "Epoch 9/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 46018.9397 - acc: 0.0000e+00 - val_loss: 48117.8360 - val_acc: 0.0000e+00\n",
      "Epoch 10/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 43169.4126 - acc: 0.0000e+00 - val_loss: 46853.6061 - val_acc: 0.0000e+00\n",
      "Epoch 11/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 42232.0810 - acc: 0.0000e+00 - val_loss: 45898.7684 - val_acc: 0.0000e+00\n",
      "Epoch 12/1200\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 39718.4482 - acc: 0.0000e+00 - val_loss: 49872.3361 - val_acc: 0.0000e+00\n",
      "Epoch 13/1200\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 38987.1954 - acc: 0.0000e+00 - val_loss: 44741.4858 - val_acc: 0.0000e+00\n",
      "Epoch 14/1200\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: 38599.2581 - acc: 0.0000e+00 - val_loss: 45958.9869 - val_acc: 0.0000e+00\n",
      "Epoch 15/1200\n",
      "1137/1137 [==============================] - 0s 327us/step - loss: 37639.4989 - acc: 8.7951e-04 - val_loss: 45401.9861 - val_acc: 0.0000e+00\n",
      "Epoch 16/1200\n",
      "1137/1137 [==============================] - 0s 214us/step - loss: 36855.6844 - acc: 0.0000e+00 - val_loss: 44481.2092 - val_acc: 0.0000e+00\n",
      "Epoch 17/1200\n",
      "1137/1137 [==============================] - 0s 222us/step - loss: 36740.8071 - acc: 0.0000e+00 - val_loss: 45895.4188 - val_acc: 0.0000e+00\n",
      "Epoch 18/1200\n",
      "1137/1137 [==============================] - 0s 200us/step - loss: 36863.8821 - acc: 0.0000e+00 - val_loss: 44937.9912 - val_acc: 0.0000e+00\n",
      "Epoch 19/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 36857.7466 - acc: 0.0000e+00 - val_loss: 44971.2544 - val_acc: 0.0000e+00\n",
      "Epoch 20/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 36277.9687 - acc: 0.0000e+00 - val_loss: 44307.1126 - val_acc: 0.0000e+00\n",
      "Epoch 21/1200\n",
      "1137/1137 [==============================] - 0s 168us/step - loss: 36267.5786 - acc: 0.0000e+00 - val_loss: 44441.8182 - val_acc: 0.0000e+00\n",
      "Epoch 22/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 36375.1404 - acc: 0.0000e+00 - val_loss: 45179.0030 - val_acc: 0.0000e+00\n",
      "Epoch 23/1200\n",
      "1137/1137 [==============================] - 0s 170us/step - loss: 36146.6287 - acc: 0.0000e+00 - val_loss: 46356.1900 - val_acc: 0.0000e+00\n",
      "Epoch 24/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 35762.4713 - acc: 0.0000e+00 - val_loss: 44365.9035 - val_acc: 0.0000e+00\n",
      "Epoch 25/1200\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: 36528.4867 - acc: 0.0000e+00 - val_loss: 45305.5085 - val_acc: 0.0000e+00\n",
      "Epoch 26/1200\n",
      "1137/1137 [==============================] - 0s 191us/step - loss: 35975.6505 - acc: 0.0000e+00 - val_loss: 44297.0223 - val_acc: 0.0000e+00\n",
      "Epoch 27/1200\n",
      "1137/1137 [==============================] - 0s 234us/step - loss: 36612.6516 - acc: 0.0000e+00 - val_loss: 44852.5159 - val_acc: 0.0000e+00\n",
      "Epoch 28/1200\n",
      "1137/1137 [==============================] - 0s 187us/step - loss: 36117.6580 - acc: 0.0000e+00 - val_loss: 45609.3896 - val_acc: 0.0000e+00\n",
      "Epoch 29/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 35583.7369 - acc: 0.0000e+00 - val_loss: 44429.4149 - val_acc: 0.0000e+00\n",
      "Epoch 30/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 35891.9463 - acc: 0.0000e+00 - val_loss: 44190.7769 - val_acc: 0.0000e+00\n",
      "Epoch 31/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 35735.4498 - acc: 0.0000e+00 - val_loss: 44180.3035 - val_acc: 0.0000e+00\n",
      "Epoch 32/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 35447.4379 - acc: 0.0000e+00 - val_loss: 44693.1426 - val_acc: 0.0000e+00\n",
      "Epoch 33/1200\n",
      "1137/1137 [==============================] - 0s 168us/step - loss: 35539.7065 - acc: 0.0000e+00 - val_loss: 44096.4994 - val_acc: 0.0000e+00\n",
      "Epoch 34/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 35558.6599 - acc: 0.0000e+00 - val_loss: 43691.6007 - val_acc: 0.0000e+00\n",
      "Epoch 35/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 35381.9562 - acc: 0.0000e+00 - val_loss: 43764.7462 - val_acc: 0.0000e+00\n",
      "Epoch 36/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 34878.4759 - acc: 0.0000e+00 - val_loss: 44874.8251 - val_acc: 0.0000e+00\n",
      "Epoch 37/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 35102.8179 - acc: 0.0000e+00 - val_loss: 44177.6329 - val_acc: 0.0000e+00\n",
      "Epoch 38/1200\n",
      "1137/1137 [==============================] - 0s 164us/step - loss: 34802.4773 - acc: 0.0000e+00 - val_loss: 45476.2408 - val_acc: 0.0000e+00\n",
      "Epoch 39/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 35097.5968 - acc: 0.0000e+00 - val_loss: 43997.9435 - val_acc: 0.0000e+00\n",
      "Epoch 40/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 35173.1634 - acc: 0.0000e+00 - val_loss: 43727.3440 - val_acc: 0.0000e+00\n",
      "Epoch 41/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 34738.1669 - acc: 0.0000e+00 - val_loss: 43847.0349 - val_acc: 0.0000e+00\n",
      "Epoch 42/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 34898.1853 - acc: 0.0000e+00 - val_loss: 43603.2571 - val_acc: 0.0000e+00\n",
      "Epoch 43/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 34497.2217 - acc: 0.0000e+00 - val_loss: 44378.6258 - val_acc: 0.0000e+00\n",
      "Epoch 44/1200\n",
      "1137/1137 [==============================] - 0s 167us/step - loss: 34149.8401 - acc: 0.0000e+00 - val_loss: 43494.8245 - val_acc: 0.0000e+00\n",
      "Epoch 45/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 34438.9186 - acc: 0.0000e+00 - val_loss: 44046.8342 - val_acc: 0.0000e+00\n",
      "Epoch 46/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 34406.7331 - acc: 0.0000e+00 - val_loss: 43824.4951 - val_acc: 0.0000e+00\n",
      "Epoch 47/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 34663.2438 - acc: 0.0000e+00 - val_loss: 43596.3102 - val_acc: 0.0000e+00\n",
      "Epoch 48/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 33946.8835 - acc: 0.0000e+00 - val_loss: 43455.3923 - val_acc: 0.0000e+00\n",
      "Epoch 49/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 34796.6646 - acc: 0.0000e+00 - val_loss: 45465.5395 - val_acc: 0.0000e+00\n",
      "Epoch 50/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 34390.8778 - acc: 0.0000e+00 - val_loss: 44208.2065 - val_acc: 0.0000e+00\n",
      "Epoch 51/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 34172.1146 - acc: 0.0000e+00 - val_loss: 46008.2506 - val_acc: 0.0000e+00\n",
      "Epoch 52/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 33704.9041 - acc: 0.0000e+00 - val_loss: 43868.9871 - val_acc: 0.0000e+00\n",
      "Epoch 53/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 147us/step - loss: 34201.6888 - acc: 0.0000e+00 - val_loss: 44255.8866 - val_acc: 0.0000e+00\n",
      "Epoch 54/1200\n",
      "1137/1137 [==============================] - 0s 233us/step - loss: 33756.7460 - acc: 0.0000e+00 - val_loss: 43419.1951 - val_acc: 0.0000e+00\n",
      "Epoch 55/1200\n",
      "1137/1137 [==============================] - 0s 227us/step - loss: 33646.0394 - acc: 0.0000e+00 - val_loss: 44023.4775 - val_acc: 0.0000e+00\n",
      "Epoch 56/1200\n",
      "1137/1137 [==============================] - 0s 195us/step - loss: 33750.6609 - acc: 0.0000e+00 - val_loss: 44076.7992 - val_acc: 0.0000e+00\n",
      "Epoch 57/1200\n",
      "1137/1137 [==============================] - 0s 169us/step - loss: 33834.2346 - acc: 0.0000e+00 - val_loss: 43458.9556 - val_acc: 0.0000e+00\n",
      "Epoch 58/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 33226.9340 - acc: 0.0000e+00 - val_loss: 43319.3677 - val_acc: 0.0000e+00\n",
      "Epoch 59/1200\n",
      "1137/1137 [==============================] - 0s 170us/step - loss: 33709.1159 - acc: 0.0000e+00 - val_loss: 43895.2993 - val_acc: 0.0000e+00\n",
      "Epoch 60/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 33483.2982 - acc: 0.0000e+00 - val_loss: 44017.3081 - val_acc: 0.0000e+00\n",
      "Epoch 61/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 33222.5193 - acc: 0.0000e+00 - val_loss: 43643.4674 - val_acc: 0.0000e+00\n",
      "Epoch 62/1200\n",
      "1137/1137 [==============================] - 0s 175us/step - loss: 33429.1402 - acc: 0.0000e+00 - val_loss: 43853.5012 - val_acc: 0.0000e+00\n",
      "Epoch 63/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 33099.1402 - acc: 0.0000e+00 - val_loss: 44143.7864 - val_acc: 0.0000e+00\n",
      "Epoch 64/1200\n",
      "1137/1137 [==============================] - 0s 169us/step - loss: 33430.0008 - acc: 0.0000e+00 - val_loss: 43865.2881 - val_acc: 0.0000e+00\n",
      "Epoch 65/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 32777.9083 - acc: 0.0000e+00 - val_loss: 43793.8079 - val_acc: 0.0000e+00\n",
      "Epoch 66/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 32860.1650 - acc: 0.0000e+00 - val_loss: 44777.8141 - val_acc: 0.0000e+00\n",
      "Epoch 67/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 32868.7276 - acc: 0.0000e+00 - val_loss: 44101.7734 - val_acc: 0.0000e+00\n",
      "Epoch 68/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 32832.8518 - acc: 0.0000e+00 - val_loss: 43680.0170 - val_acc: 0.0000e+00\n",
      "Epoch 69/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 32375.1901 - acc: 0.0000e+00 - val_loss: 43820.0201 - val_acc: 0.0000e+00\n",
      "Epoch 70/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 32472.5119 - acc: 8.7951e-04 - val_loss: 43773.5794 - val_acc: 0.0000e+00\n",
      "Epoch 71/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 32703.1450 - acc: 0.0000e+00 - val_loss: 44242.2910 - val_acc: 0.0000e+00\n",
      "Epoch 72/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 32112.6839 - acc: 0.0000e+00 - val_loss: 44191.1799 - val_acc: 0.0000e+00\n",
      "Epoch 73/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 32797.6696 - acc: 0.0000e+00 - val_loss: 43881.3819 - val_acc: 0.0000e+00\n",
      "Epoch 74/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 31574.1319 - acc: 0.0000e+00 - val_loss: 43947.6885 - val_acc: 0.0000e+00\n",
      "Epoch 75/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 32541.0148 - acc: 8.7951e-04 - val_loss: 44437.7139 - val_acc: 0.0000e+00\n",
      "Epoch 76/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 32096.6989 - acc: 8.7951e-04 - val_loss: 44673.5670 - val_acc: 0.0000e+00\n",
      "Epoch 77/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 32401.4269 - acc: 0.0000e+00 - val_loss: 47084.4927 - val_acc: 0.0000e+00\n",
      "Epoch 78/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 32355.6310 - acc: 0.0000e+00 - val_loss: 46035.4005 - val_acc: 0.0000e+00\n",
      "Epoch 79/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 32590.4416 - acc: 0.0000e+00 - val_loss: 44616.1954 - val_acc: 0.0000e+00\n",
      "Epoch 80/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 31951.6881 - acc: 0.0000e+00 - val_loss: 44242.1760 - val_acc: 0.0000e+00\n",
      "Epoch 81/1200\n",
      "1137/1137 [==============================] - 0s 167us/step - loss: 32169.2771 - acc: 0.0000e+00 - val_loss: 45351.4369 - val_acc: 0.0000e+00\n",
      "Epoch 82/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 32430.2337 - acc: 0.0000e+00 - val_loss: 45892.3771 - val_acc: 0.0000e+00\n",
      "Epoch 83/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 32062.7750 - acc: 0.0000e+00 - val_loss: 44138.3800 - val_acc: 0.0000e+00\n",
      "Epoch 84/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 32630.7125 - acc: 0.0000e+00 - val_loss: 44231.7994 - val_acc: 0.0000e+00\n",
      "Epoch 85/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 31600.9056 - acc: 0.0000e+00 - val_loss: 44296.3856 - val_acc: 0.0000e+00\n",
      "Epoch 86/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 31825.5095 - acc: 0.0000e+00 - val_loss: 44684.6572 - val_acc: 0.0000e+00\n",
      "Epoch 87/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 32055.1899 - acc: 0.0000e+00 - val_loss: 44394.4236 - val_acc: 0.0000e+00\n",
      "Epoch 88/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 31530.5278 - acc: 0.0000e+00 - val_loss: 44696.8966 - val_acc: 0.0000e+00\n",
      "Epoch 89/1200\n",
      "1137/1137 [==============================] - 0s 199us/step - loss: 31771.7513 - acc: 0.0000e+00 - val_loss: 44607.9380 - val_acc: 0.0000e+00\n",
      "Epoch 90/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 31698.6994 - acc: 0.0000e+00 - val_loss: 44727.8125 - val_acc: 0.0000e+00\n",
      "Epoch 91/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 31589.7829 - acc: 0.0000e+00 - val_loss: 44412.0175 - val_acc: 0.0000e+00\n",
      "Epoch 92/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 33156.1679 - acc: 0.0000e+00 - val_loss: 44943.6857 - val_acc: 0.0000e+00\n",
      "Epoch 93/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 31777.3769 - acc: 0.0000e+00 - val_loss: 46121.9325 - val_acc: 0.0000e+00\n",
      "Epoch 94/1200\n",
      "1137/1137 [==============================] - 0s 174us/step - loss: 31742.2085 - acc: 0.0000e+00 - val_loss: 45944.2819 - val_acc: 0.0000e+00\n",
      "Epoch 95/1200\n",
      "1137/1137 [==============================] - 0s 189us/step - loss: 31806.6166 - acc: 0.0000e+00 - val_loss: 45247.0493 - val_acc: 0.0000e+00\n",
      "Epoch 96/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 31999.7201 - acc: 0.0000e+00 - val_loss: 45181.3714 - val_acc: 0.0000e+00\n",
      "Epoch 97/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 31538.0819 - acc: 0.0000e+00 - val_loss: 44642.8542 - val_acc: 0.0000e+00\n",
      "Epoch 98/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 31225.2054 - acc: 0.0000e+00 - val_loss: 45354.4303 - val_acc: 0.0000e+00\n",
      "Epoch 99/1200\n",
      "1137/1137 [==============================] - 0s 176us/step - loss: 31546.2477 - acc: 0.0000e+00 - val_loss: 44965.1064 - val_acc: 0.0000e+00\n",
      "Epoch 100/1200\n",
      "1137/1137 [==============================] - 0s 179us/step - loss: 31701.7591 - acc: 0.0000e+00 - val_loss: 45287.6941 - val_acc: 0.0000e+00\n",
      "Epoch 101/1200\n",
      "1137/1137 [==============================] - 0s 175us/step - loss: 31510.9925 - acc: 0.0000e+00 - val_loss: 44117.4616 - val_acc: 0.0000e+00\n",
      "Epoch 102/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 30956.9057 - acc: 0.0000e+00 - val_loss: 45430.4135 - val_acc: 0.0000e+00\n",
      "Epoch 103/1200\n",
      "1137/1137 [==============================] - 0s 168us/step - loss: 31598.6937 - acc: 0.0000e+00 - val_loss: 46336.9390 - val_acc: 0.0000e+00\n",
      "Epoch 104/1200\n",
      "1137/1137 [==============================] - 0s 165us/step - loss: 31501.4672 - acc: 0.0000e+00 - val_loss: 44484.2296 - val_acc: 0.0000e+00\n",
      "Epoch 105/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 31230.6039 - acc: 0.0000e+00 - val_loss: 44576.3250 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 30743.8887 - acc: 0.0000e+00 - val_loss: 44185.0548 - val_acc: 0.0000e+00\n",
      "Epoch 107/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 31190.2997 - acc: 0.0000e+00 - val_loss: 43975.7012 - val_acc: 0.0000e+00\n",
      "Epoch 108/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 31053.4407 - acc: 0.0000e+00 - val_loss: 44506.0877 - val_acc: 0.0000e+00\n",
      "Epoch 109/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 31152.0819 - acc: 0.0000e+00 - val_loss: 44559.4410 - val_acc: 0.0000e+00\n",
      "Epoch 110/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 31346.5384 - acc: 0.0000e+00 - val_loss: 44375.4274 - val_acc: 0.0000e+00\n",
      "Epoch 111/1200\n",
      "1137/1137 [==============================] - 0s 169us/step - loss: 31208.4808 - acc: 0.0000e+00 - val_loss: 44583.0526 - val_acc: 0.0000e+00\n",
      "Epoch 112/1200\n",
      "1137/1137 [==============================] - 0s 170us/step - loss: 31252.0353 - acc: 0.0000e+00 - val_loss: 44459.3681 - val_acc: 0.0000e+00\n",
      "Epoch 113/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 31230.4793 - acc: 0.0000e+00 - val_loss: 44661.9596 - val_acc: 0.0000e+00\n",
      "Epoch 114/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 31084.1709 - acc: 0.0000e+00 - val_loss: 44125.1527 - val_acc: 0.0000e+00\n",
      "Epoch 115/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 30753.6998 - acc: 0.0000e+00 - val_loss: 46400.0837 - val_acc: 0.0000e+00\n",
      "Epoch 116/1200\n",
      "1137/1137 [==============================] - 0s 176us/step - loss: 31683.5950 - acc: 0.0000e+00 - val_loss: 44381.2296 - val_acc: 0.0000e+00\n",
      "Epoch 117/1200\n",
      "1137/1137 [==============================] - 0s 169us/step - loss: 31022.6964 - acc: 0.0000e+00 - val_loss: 44107.2434 - val_acc: 0.0000e+00\n",
      "Epoch 118/1200\n",
      "1137/1137 [==============================] - 0s 165us/step - loss: 31149.7279 - acc: 0.0000e+00 - val_loss: 48239.5384 - val_acc: 0.0000e+00\n",
      "Epoch 119/1200\n",
      "1137/1137 [==============================] - 0s 164us/step - loss: 30977.3222 - acc: 0.0000e+00 - val_loss: 44349.8303 - val_acc: 0.0000e+00\n",
      "Epoch 120/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 30863.8355 - acc: 0.0000e+00 - val_loss: 44977.6811 - val_acc: 0.0000e+00\n",
      "Epoch 121/1200\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 30565.7622 - acc: 0.0000e+00 - val_loss: 44119.6999 - val_acc: 0.0000e+00\n",
      "Epoch 122/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 31577.7391 - acc: 0.0000e+00 - val_loss: 45192.3040 - val_acc: 0.0000e+00\n",
      "Epoch 123/1200\n",
      "1137/1137 [==============================] - 0s 173us/step - loss: 30585.7455 - acc: 0.0000e+00 - val_loss: 44713.2160 - val_acc: 0.0000e+00\n",
      "Epoch 124/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 30637.0823 - acc: 0.0000e+00 - val_loss: 44430.8314 - val_acc: 0.0000e+00\n",
      "Epoch 125/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 30386.0145 - acc: 0.0000e+00 - val_loss: 45599.6460 - val_acc: 0.0000e+00\n",
      "Epoch 126/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 30492.4386 - acc: 0.0000e+00 - val_loss: 44027.2777 - val_acc: 0.0000e+00\n",
      "Epoch 127/1200\n",
      "1137/1137 [==============================] - 0s 169us/step - loss: 31107.0977 - acc: 0.0000e+00 - val_loss: 47245.5500 - val_acc: 0.0000e+00\n",
      "Epoch 128/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 30450.0590 - acc: 0.0000e+00 - val_loss: 44716.4813 - val_acc: 0.0000e+00\n",
      "Epoch 129/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 30503.2212 - acc: 0.0000e+00 - val_loss: 44274.0639 - val_acc: 0.0000e+00\n",
      "Epoch 130/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 30744.1314 - acc: 0.0000e+00 - val_loss: 44529.2464 - val_acc: 0.0000e+00\n",
      "Epoch 131/1200\n",
      "1137/1137 [==============================] - 0s 165us/step - loss: 30570.8795 - acc: 0.0000e+00 - val_loss: 47510.2430 - val_acc: 0.0000e+00\n",
      "Epoch 132/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 30677.1476 - acc: 0.0000e+00 - val_loss: 44238.0879 - val_acc: 0.0000e+00\n",
      "Epoch 133/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 30400.8387 - acc: 0.0000e+00 - val_loss: 45449.9000 - val_acc: 0.0000e+00\n",
      "Epoch 134/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 30273.3225 - acc: 0.0000e+00 - val_loss: 44417.2012 - val_acc: 0.0000e+00\n",
      "Epoch 135/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 30492.8582 - acc: 0.0000e+00 - val_loss: 44310.9140 - val_acc: 0.0000e+00\n",
      "Epoch 136/1200\n",
      "1137/1137 [==============================] - 0s 164us/step - loss: 30228.0732 - acc: 0.0000e+00 - val_loss: 44313.7698 - val_acc: 0.0000e+00\n",
      "Epoch 137/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 30323.5054 - acc: 0.0000e+00 - val_loss: 44116.8667 - val_acc: 0.0000e+00\n",
      "Epoch 138/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 30662.2874 - acc: 0.0000e+00 - val_loss: 44028.8641 - val_acc: 0.0000e+00\n",
      "Epoch 139/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 29749.2604 - acc: 0.0000e+00 - val_loss: 45455.8953 - val_acc: 0.0000e+00\n",
      "Epoch 140/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 30415.0724 - acc: 0.0000e+00 - val_loss: 44191.7075 - val_acc: 0.0000e+00\n",
      "Epoch 141/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 30275.8287 - acc: 0.0000e+00 - val_loss: 45356.6125 - val_acc: 0.0000e+00\n",
      "Epoch 142/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 30197.7315 - acc: 0.0000e+00 - val_loss: 43962.3718 - val_acc: 0.0000e+00\n",
      "Epoch 143/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 29752.7711 - acc: 0.0000e+00 - val_loss: 44155.5954 - val_acc: 0.0000e+00\n",
      "Epoch 144/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 29779.3534 - acc: 0.0000e+00 - val_loss: 44075.2363 - val_acc: 0.0000e+00\n",
      "Epoch 145/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 30091.1619 - acc: 0.0000e+00 - val_loss: 43766.1212 - val_acc: 0.0000e+00\n",
      "Epoch 146/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 30092.9389 - acc: 0.0000e+00 - val_loss: 44334.2130 - val_acc: 0.0000e+00\n",
      "Epoch 147/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 29925.2737 - acc: 0.0000e+00 - val_loss: 44356.8711 - val_acc: 0.0000e+00\n",
      "Epoch 148/1200\n",
      "1137/1137 [==============================] - 0s 184us/step - loss: 30335.6465 - acc: 0.0000e+00 - val_loss: 45828.4630 - val_acc: 0.0000e+00\n",
      "Epoch 149/1200\n",
      "1137/1137 [==============================] - 0s 167us/step - loss: 30068.3068 - acc: 0.0000e+00 - val_loss: 44603.0872 - val_acc: 0.0000e+00\n",
      "Epoch 150/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 30280.9332 - acc: 0.0000e+00 - val_loss: 45511.9430 - val_acc: 0.0000e+00\n",
      "Epoch 151/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 30122.6322 - acc: 0.0000e+00 - val_loss: 44398.8890 - val_acc: 0.0000e+00\n",
      "Epoch 152/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 29369.6692 - acc: 0.0000e+00 - val_loss: 44030.8277 - val_acc: 0.0000e+00\n",
      "Epoch 153/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 29817.6456 - acc: 0.0000e+00 - val_loss: 44421.6871 - val_acc: 0.0000e+00\n",
      "Epoch 154/1200\n",
      "1137/1137 [==============================] - 0s 182us/step - loss: 29751.5336 - acc: 0.0000e+00 - val_loss: 43970.2129 - val_acc: 0.0000e+00\n",
      "Epoch 155/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 29586.8345 - acc: 0.0000e+00 - val_loss: 44826.0949 - val_acc: 0.0000e+00\n",
      "Epoch 156/1200\n",
      "1137/1137 [==============================] - 0s 171us/step - loss: 29517.7134 - acc: 0.0000e+00 - val_loss: 44129.9482 - val_acc: 0.0000e+00\n",
      "Epoch 157/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 29682.5268 - acc: 0.0000e+00 - val_loss: 44143.2501 - val_acc: 0.0000e+00\n",
      "Epoch 158/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 182us/step - loss: 29571.2752 - acc: 0.0000e+00 - val_loss: 45443.4077 - val_acc: 0.0000e+00\n",
      "Epoch 159/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 29303.3016 - acc: 0.0000e+00 - val_loss: 43762.0395 - val_acc: 0.0000e+00\n",
      "Epoch 160/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 29527.5092 - acc: 0.0000e+00 - val_loss: 43965.9929 - val_acc: 0.0000e+00\n",
      "Epoch 161/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 29360.5942 - acc: 0.0000e+00 - val_loss: 43852.8450 - val_acc: 0.0000e+00\n",
      "Epoch 162/1200\n",
      "1137/1137 [==============================] - 0s 170us/step - loss: 29147.3278 - acc: 0.0000e+00 - val_loss: 47613.0643 - val_acc: 0.0000e+00\n",
      "Epoch 163/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 28964.6276 - acc: 0.0000e+00 - val_loss: 43353.6103 - val_acc: 0.0000e+00\n",
      "Epoch 164/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 28663.2872 - acc: 0.0000e+00 - val_loss: 45268.5328 - val_acc: 0.0000e+00\n",
      "Epoch 165/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 29006.8279 - acc: 0.0000e+00 - val_loss: 44912.8627 - val_acc: 0.0000e+00\n",
      "Epoch 166/1200\n",
      "1137/1137 [==============================] - 0s 173us/step - loss: 29423.2891 - acc: 0.0000e+00 - val_loss: 43350.2558 - val_acc: 0.0000e+00\n",
      "Epoch 167/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 29022.9315 - acc: 0.0000e+00 - val_loss: 43091.8806 - val_acc: 0.0000e+00\n",
      "Epoch 168/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 29170.7586 - acc: 0.0000e+00 - val_loss: 44172.8722 - val_acc: 0.0000e+00\n",
      "Epoch 169/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 28792.4516 - acc: 0.0000e+00 - val_loss: 45068.1070 - val_acc: 0.0000e+00\n",
      "Epoch 170/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 29060.8578 - acc: 0.0000e+00 - val_loss: 45194.5782 - val_acc: 0.0000e+00\n",
      "Epoch 171/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 29158.5554 - acc: 0.0000e+00 - val_loss: 44681.6573 - val_acc: 0.0000e+00\n",
      "Epoch 172/1200\n",
      "1137/1137 [==============================] - 0s 165us/step - loss: 29036.1667 - acc: 0.0000e+00 - val_loss: 44178.6260 - val_acc: 0.0000e+00\n",
      "Epoch 173/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 29394.6927 - acc: 0.0000e+00 - val_loss: 44744.7179 - val_acc: 0.0000e+00\n",
      "Epoch 174/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 28896.6915 - acc: 0.0000e+00 - val_loss: 44098.4290 - val_acc: 0.0000e+00\n",
      "Epoch 175/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 28657.0661 - acc: 0.0000e+00 - val_loss: 43382.9929 - val_acc: 0.0000e+00\n",
      "Epoch 176/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 28422.5332 - acc: 0.0000e+00 - val_loss: 43097.6786 - val_acc: 0.0000e+00\n",
      "Epoch 177/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 28830.5208 - acc: 0.0000e+00 - val_loss: 43670.1581 - val_acc: 0.0000e+00\n",
      "Epoch 178/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 28759.7054 - acc: 0.0000e+00 - val_loss: 45071.3452 - val_acc: 0.0000e+00\n",
      "Epoch 179/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 28378.4359 - acc: 0.0000e+00 - val_loss: 43943.7120 - val_acc: 0.0000e+00\n",
      "Epoch 180/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 28657.3405 - acc: 0.0000e+00 - val_loss: 43964.9309 - val_acc: 0.0000e+00\n",
      "Epoch 181/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 28695.0599 - acc: 0.0000e+00 - val_loss: 45089.1386 - val_acc: 0.0000e+00\n",
      "Epoch 182/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 28091.5016 - acc: 0.0000e+00 - val_loss: 43232.4180 - val_acc: 0.0000e+00\n",
      "Epoch 183/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 28892.7436 - acc: 0.0000e+00 - val_loss: 43685.6463 - val_acc: 0.0000e+00\n",
      "Epoch 184/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 29017.6445 - acc: 0.0000e+00 - val_loss: 48397.1190 - val_acc: 0.0000e+00\n",
      "Epoch 185/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 28728.0680 - acc: 0.0000e+00 - val_loss: 42474.8520 - val_acc: 0.0000e+00\n",
      "Epoch 186/1200\n",
      "1137/1137 [==============================] - 0s 165us/step - loss: 28417.6625 - acc: 0.0000e+00 - val_loss: 42729.2183 - val_acc: 0.0000e+00\n",
      "Epoch 187/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 28253.6823 - acc: 0.0000e+00 - val_loss: 42949.1471 - val_acc: 0.0000e+00\n",
      "Epoch 188/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 28397.4157 - acc: 0.0000e+00 - val_loss: 44527.6838 - val_acc: 0.0000e+00\n",
      "Epoch 189/1200\n",
      "1137/1137 [==============================] - 0s 176us/step - loss: 28801.5694 - acc: 0.0000e+00 - val_loss: 43122.3964 - val_acc: 0.0000e+00\n",
      "Epoch 190/1200\n",
      "1137/1137 [==============================] - 0s 179us/step - loss: 28207.5482 - acc: 0.0000e+00 - val_loss: 43169.6224 - val_acc: 0.0000e+00\n",
      "Epoch 191/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 28494.3302 - acc: 0.0000e+00 - val_loss: 43070.0369 - val_acc: 0.0000e+00\n",
      "Epoch 192/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 28545.2669 - acc: 0.0000e+00 - val_loss: 44138.1835 - val_acc: 0.0000e+00\n",
      "Epoch 193/1200\n",
      "1137/1137 [==============================] - 0s 167us/step - loss: 28123.3956 - acc: 0.0000e+00 - val_loss: 42559.1062 - val_acc: 0.0000e+00\n",
      "Epoch 194/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 28217.3792 - acc: 0.0000e+00 - val_loss: 42470.9573 - val_acc: 0.0000e+00\n",
      "Epoch 195/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 28756.1114 - acc: 0.0000e+00 - val_loss: 45074.8237 - val_acc: 0.0000e+00\n",
      "Epoch 196/1200\n",
      "1137/1137 [==============================] - 0s 175us/step - loss: 28099.4203 - acc: 0.0000e+00 - val_loss: 43354.6497 - val_acc: 0.0000e+00\n",
      "Epoch 197/1200\n",
      "1137/1137 [==============================] - 0s 188us/step - loss: 27870.9323 - acc: 0.0000e+00 - val_loss: 44602.5021 - val_acc: 0.0000e+00\n",
      "Epoch 198/1200\n",
      "1137/1137 [==============================] - 0s 171us/step - loss: 28547.9918 - acc: 0.0000e+00 - val_loss: 42714.9341 - val_acc: 0.0000e+00\n",
      "Epoch 199/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 28043.8698 - acc: 0.0000e+00 - val_loss: 45647.8222 - val_acc: 0.0000e+00\n",
      "Epoch 200/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 28244.5713 - acc: 0.0000e+00 - val_loss: 43049.4791 - val_acc: 0.0000e+00\n",
      "Epoch 201/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 27721.8700 - acc: 0.0000e+00 - val_loss: 43945.4684 - val_acc: 0.0000e+00\n",
      "Epoch 202/1200\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 28067.0696 - acc: 0.0000e+00 - val_loss: 43306.2324 - val_acc: 0.0000e+00\n",
      "Epoch 203/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 27617.0321 - acc: 0.0000e+00 - val_loss: 42938.1092 - val_acc: 0.0000e+00\n",
      "Epoch 204/1200\n",
      "1137/1137 [==============================] - 0s 180us/step - loss: 28628.3912 - acc: 0.0000e+00 - val_loss: 42050.6716 - val_acc: 0.0000e+00\n",
      "Epoch 205/1200\n",
      "1137/1137 [==============================] - 0s 167us/step - loss: 27481.4965 - acc: 0.0000e+00 - val_loss: 42882.3135 - val_acc: 0.0000e+00\n",
      "Epoch 206/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 27711.7419 - acc: 0.0000e+00 - val_loss: 43364.5936 - val_acc: 0.0000e+00\n",
      "Epoch 207/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 27665.3371 - acc: 0.0000e+00 - val_loss: 42509.4723 - val_acc: 0.0000e+00\n",
      "Epoch 208/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 27470.2073 - acc: 0.0000e+00 - val_loss: 43520.3040 - val_acc: 0.0000e+00\n",
      "Epoch 209/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 27592.2964 - acc: 0.0000e+00 - val_loss: 43040.4615 - val_acc: 0.0000e+00\n",
      "Epoch 210/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 180us/step - loss: 27090.1645 - acc: 0.0000e+00 - val_loss: 42311.7850 - val_acc: 0.0000e+00\n",
      "Epoch 211/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 27182.4852 - acc: 0.0000e+00 - val_loss: 43094.6565 - val_acc: 0.0000e+00\n",
      "Epoch 212/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 27057.2113 - acc: 0.0000e+00 - val_loss: 42107.0721 - val_acc: 0.0000e+00\n",
      "Epoch 213/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 27011.9064 - acc: 0.0000e+00 - val_loss: 41707.9606 - val_acc: 0.0000e+00\n",
      "Epoch 214/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 27454.5875 - acc: 0.0000e+00 - val_loss: 42266.5294 - val_acc: 0.0000e+00\n",
      "Epoch 215/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 27292.7672 - acc: 0.0000e+00 - val_loss: 43349.5647 - val_acc: 0.0000e+00\n",
      "Epoch 216/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 28374.4402 - acc: 0.0000e+00 - val_loss: 43017.9753 - val_acc: 0.0000e+00\n",
      "Epoch 217/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 27825.2895 - acc: 0.0000e+00 - val_loss: 44538.1634 - val_acc: 0.0000e+00\n",
      "Epoch 218/1200\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 27110.0879 - acc: 0.0000e+00 - val_loss: 41982.7670 - val_acc: 0.0000e+00\n",
      "Epoch 219/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 27377.5992 - acc: 0.0000e+00 - val_loss: 41674.4708 - val_acc: 0.0000e+00\n",
      "Epoch 220/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 27354.5956 - acc: 0.0000e+00 - val_loss: 41529.4864 - val_acc: 0.0000e+00\n",
      "Epoch 221/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 27932.9057 - acc: 0.0000e+00 - val_loss: 41560.3430 - val_acc: 0.0000e+00\n",
      "Epoch 222/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 27115.7999 - acc: 0.0000e+00 - val_loss: 43365.7785 - val_acc: 0.0000e+00\n",
      "Epoch 223/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 26819.0990 - acc: 0.0000e+00 - val_loss: 42734.0894 - val_acc: 0.0000e+00\n",
      "Epoch 224/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 26875.8915 - acc: 0.0000e+00 - val_loss: 41396.3184 - val_acc: 0.0000e+00\n",
      "Epoch 225/1200\n",
      "1137/1137 [==============================] - 0s 213us/step - loss: 27008.7731 - acc: 0.0000e+00 - val_loss: 42377.7305 - val_acc: 0.0000e+00\n",
      "Epoch 226/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 26850.6039 - acc: 0.0000e+00 - val_loss: 42392.0552 - val_acc: 0.0000e+00\n",
      "Epoch 227/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 26729.4864 - acc: 0.0000e+00 - val_loss: 40826.8294 - val_acc: 0.0000e+00\n",
      "Epoch 228/1200\n",
      "1137/1137 [==============================] - 0s 165us/step - loss: 25955.9643 - acc: 0.0000e+00 - val_loss: 40981.8068 - val_acc: 0.0000e+00\n",
      "Epoch 229/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 27087.8773 - acc: 0.0000e+00 - val_loss: 42204.8567 - val_acc: 0.0000e+00\n",
      "Epoch 230/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 26861.9621 - acc: 0.0000e+00 - val_loss: 40578.3100 - val_acc: 0.0000e+00\n",
      "Epoch 231/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 26548.6160 - acc: 0.0000e+00 - val_loss: 44735.1988 - val_acc: 0.0000e+00\n",
      "Epoch 232/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 27299.4495 - acc: 0.0000e+00 - val_loss: 41193.0331 - val_acc: 0.0000e+00\n",
      "Epoch 233/1200\n",
      "1137/1137 [==============================] - 0s 169us/step - loss: 26411.8820 - acc: 0.0000e+00 - val_loss: 40780.3463 - val_acc: 0.0000e+00\n",
      "Epoch 234/1200\n",
      "1137/1137 [==============================] - 0s 170us/step - loss: 26461.6954 - acc: 0.0000e+00 - val_loss: 40796.1484 - val_acc: 0.0000e+00\n",
      "Epoch 235/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 26039.1636 - acc: 0.0000e+00 - val_loss: 43912.9575 - val_acc: 0.0000e+00\n",
      "Epoch 236/1200\n",
      "1137/1137 [==============================] - 0s 175us/step - loss: 26759.4181 - acc: 0.0000e+00 - val_loss: 41149.6660 - val_acc: 0.0000e+00\n",
      "Epoch 237/1200\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 26556.6391 - acc: 0.0000e+00 - val_loss: 41103.3624 - val_acc: 0.0000e+00\n",
      "Epoch 238/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 25893.0291 - acc: 0.0000e+00 - val_loss: 41079.6198 - val_acc: 0.0000e+00\n",
      "Epoch 239/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 26450.5574 - acc: 0.0000e+00 - val_loss: 41303.5602 - val_acc: 0.0000e+00\n",
      "Epoch 240/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 26936.7699 - acc: 0.0000e+00 - val_loss: 43694.9821 - val_acc: 0.0000e+00\n",
      "Epoch 241/1200\n",
      "1137/1137 [==============================] - 0s 174us/step - loss: 26004.4928 - acc: 0.0000e+00 - val_loss: 40690.2156 - val_acc: 0.0000e+00\n",
      "Epoch 242/1200\n",
      "1137/1137 [==============================] - 0s 191us/step - loss: 26593.5502 - acc: 0.0000e+00 - val_loss: 41124.8406 - val_acc: 0.0000e+00\n",
      "Epoch 243/1200\n",
      "1137/1137 [==============================] - 0s 177us/step - loss: 26237.2834 - acc: 0.0000e+00 - val_loss: 42522.7394 - val_acc: 0.0000e+00\n",
      "Epoch 244/1200\n",
      "1137/1137 [==============================] - 0s 168us/step - loss: 26374.8056 - acc: 0.0000e+00 - val_loss: 40677.6909 - val_acc: 0.0000e+00\n",
      "Epoch 245/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 26480.6216 - acc: 8.7951e-04 - val_loss: 41016.9228 - val_acc: 0.0000e+00\n",
      "Epoch 246/1200\n",
      "1137/1137 [==============================] - 0s 175us/step - loss: 25862.8151 - acc: 0.0000e+00 - val_loss: 41662.2620 - val_acc: 0.0000e+00\n",
      "Epoch 247/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 25784.7482 - acc: 0.0000e+00 - val_loss: 40328.8527 - val_acc: 0.0000e+00\n",
      "Epoch 248/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 25456.9092 - acc: 0.0000e+00 - val_loss: 40208.8206 - val_acc: 0.0000e+00\n",
      "Epoch 249/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 25557.1145 - acc: 0.0000e+00 - val_loss: 40198.9573 - val_acc: 0.0000e+00\n",
      "Epoch 250/1200\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 25619.3952 - acc: 0.0000e+00 - val_loss: 40222.7913 - val_acc: 0.0000e+00\n",
      "Epoch 251/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 25433.7484 - acc: 0.0000e+00 - val_loss: 41262.1280 - val_acc: 0.0000e+00\n",
      "Epoch 252/1200\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 25091.8851 - acc: 0.0000e+00 - val_loss: 39877.5440 - val_acc: 0.0000e+00\n",
      "Epoch 253/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 25015.7287 - acc: 0.0000e+00 - val_loss: 40261.5529 - val_acc: 0.0000e+00\n",
      "Epoch 254/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 25400.3370 - acc: 0.0000e+00 - val_loss: 39767.5505 - val_acc: 0.0000e+00\n",
      "Epoch 255/1200\n",
      "1137/1137 [==============================] - 0s 200us/step - loss: 25085.2177 - acc: 0.0000e+00 - val_loss: 41365.9334 - val_acc: 0.0000e+00\n",
      "Epoch 256/1200\n",
      "1137/1137 [==============================] - 0s 336us/step - loss: 24825.6117 - acc: 0.0000e+00 - val_loss: 40247.0510 - val_acc: 0.0000e+00\n",
      "Epoch 257/1200\n",
      "1137/1137 [==============================] - 0s 331us/step - loss: 25264.0581 - acc: 0.0000e+00 - val_loss: 39667.0265 - val_acc: 0.0000e+00\n",
      "Epoch 258/1200\n",
      "1137/1137 [==============================] - 0s 238us/step - loss: 25588.0787 - acc: 0.0000e+00 - val_loss: 40541.9529 - val_acc: 0.0000e+00\n",
      "Epoch 259/1200\n",
      "1137/1137 [==============================] - 0s 239us/step - loss: 25623.0505 - acc: 0.0000e+00 - val_loss: 42249.1462 - val_acc: 0.0000e+00\n",
      "Epoch 260/1200\n",
      "1137/1137 [==============================] - 0s 229us/step - loss: 25332.6912 - acc: 0.0000e+00 - val_loss: 41421.1190 - val_acc: 0.0000e+00\n",
      "Epoch 261/1200\n",
      "1137/1137 [==============================] - 0s 215us/step - loss: 25567.0086 - acc: 0.0000e+00 - val_loss: 41046.5881 - val_acc: 0.0000e+00\n",
      "Epoch 262/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 181us/step - loss: 26058.7656 - acc: 0.0000e+00 - val_loss: 39527.6119 - val_acc: 0.0000e+00\n",
      "Epoch 263/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 25171.1805 - acc: 0.0000e+00 - val_loss: 39816.1626 - val_acc: 0.0000e+00\n",
      "Epoch 264/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 24841.9373 - acc: 0.0000e+00 - val_loss: 39635.4615 - val_acc: 0.0000e+00\n",
      "Epoch 265/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 25383.2074 - acc: 0.0000e+00 - val_loss: 39672.8361 - val_acc: 0.0000e+00\n",
      "Epoch 266/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 25556.3758 - acc: 0.0000e+00 - val_loss: 40517.7472 - val_acc: 0.0000e+00\n",
      "Epoch 267/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 25009.3674 - acc: 0.0000e+00 - val_loss: 39984.6410 - val_acc: 0.0000e+00\n",
      "Epoch 268/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 25021.1130 - acc: 0.0000e+00 - val_loss: 39456.8688 - val_acc: 0.0000e+00\n",
      "Epoch 269/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 24640.9053 - acc: 0.0000e+00 - val_loss: 38784.0126 - val_acc: 0.0000e+00\n",
      "Epoch 270/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 25032.6826 - acc: 0.0000e+00 - val_loss: 42042.1465 - val_acc: 0.0000e+00\n",
      "Epoch 271/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 24989.8351 - acc: 0.0000e+00 - val_loss: 39860.3729 - val_acc: 0.0000e+00\n",
      "Epoch 272/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 25206.9071 - acc: 0.0000e+00 - val_loss: 39112.1514 - val_acc: 0.0000e+00\n",
      "Epoch 273/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 25228.9972 - acc: 0.0000e+00 - val_loss: 40697.4548 - val_acc: 0.0000e+00\n",
      "Epoch 274/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 24880.0822 - acc: 0.0000e+00 - val_loss: 39689.8584 - val_acc: 0.0000e+00\n",
      "Epoch 275/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 25121.7439 - acc: 0.0000e+00 - val_loss: 42018.9943 - val_acc: 0.0000e+00\n",
      "Epoch 276/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 24908.9783 - acc: 0.0000e+00 - val_loss: 38945.3435 - val_acc: 0.0000e+00\n",
      "Epoch 277/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 24387.7592 - acc: 0.0000e+00 - val_loss: 39849.2492 - val_acc: 0.0000e+00\n",
      "Epoch 278/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 25175.4248 - acc: 0.0000e+00 - val_loss: 38482.4419 - val_acc: 0.0000e+00\n",
      "Epoch 279/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 24699.1307 - acc: 0.0000e+00 - val_loss: 38609.0012 - val_acc: 0.0000e+00\n",
      "Epoch 280/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 25417.8868 - acc: 0.0000e+00 - val_loss: 40000.5412 - val_acc: 0.0000e+00\n",
      "Epoch 281/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 24949.3851 - acc: 0.0000e+00 - val_loss: 38816.2750 - val_acc: 0.0000e+00\n",
      "Epoch 282/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 24222.4912 - acc: 0.0000e+00 - val_loss: 41986.5906 - val_acc: 0.0000e+00\n",
      "Epoch 283/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 24978.3189 - acc: 0.0000e+00 - val_loss: 40081.0270 - val_acc: 0.0000e+00\n",
      "Epoch 284/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 24549.3457 - acc: 0.0000e+00 - val_loss: 39048.0366 - val_acc: 0.0000e+00\n",
      "Epoch 285/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 24423.7063 - acc: 0.0000e+00 - val_loss: 38717.5810 - val_acc: 0.0000e+00\n",
      "Epoch 286/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 25065.8884 - acc: 0.0000e+00 - val_loss: 37858.6609 - val_acc: 0.0000e+00\n",
      "Epoch 287/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 24482.1931 - acc: 0.0000e+00 - val_loss: 39062.0043 - val_acc: 0.0000e+00\n",
      "Epoch 288/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 24142.4953 - acc: 0.0000e+00 - val_loss: 37786.8085 - val_acc: 0.0000e+00\n",
      "Epoch 289/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 24554.1490 - acc: 0.0000e+00 - val_loss: 37673.4654 - val_acc: 0.0000e+00\n",
      "Epoch 290/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 24463.7448 - acc: 0.0000e+00 - val_loss: 38972.3440 - val_acc: 0.0000e+00\n",
      "Epoch 291/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 24353.2144 - acc: 0.0000e+00 - val_loss: 37844.3149 - val_acc: 0.0000e+00\n",
      "Epoch 292/1200\n",
      "1137/1137 [==============================] - 0s 228us/step - loss: 24236.4338 - acc: 0.0000e+00 - val_loss: 38838.5177 - val_acc: 0.0000e+00\n",
      "Epoch 293/1200\n",
      "1137/1137 [==============================] - 0s 248us/step - loss: 24254.5607 - acc: 0.0000e+00 - val_loss: 38758.6661 - val_acc: 0.0000e+00\n",
      "Epoch 294/1200\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 24069.1369 - acc: 0.0000e+00 - val_loss: 38763.7848 - val_acc: 0.0000e+00\n",
      "Epoch 295/1200\n",
      "1137/1137 [==============================] - 0s 329us/step - loss: 23759.0751 - acc: 0.0000e+00 - val_loss: 37278.0515 - val_acc: 0.0000e+00\n",
      "Epoch 296/1200\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 26060.1547 - acc: 0.0000e+00 - val_loss: 38656.7362 - val_acc: 0.0000e+00\n",
      "Epoch 297/1200\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 24101.3634 - acc: 0.0000e+00 - val_loss: 37715.5011 - val_acc: 0.0000e+00\n",
      "Epoch 298/1200\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: 24759.6571 - acc: 0.0000e+00 - val_loss: 39245.1601 - val_acc: 0.0000e+00\n",
      "Epoch 299/1200\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 24633.2349 - acc: 0.0000e+00 - val_loss: 38729.2737 - val_acc: 0.0000e+00\n",
      "Epoch 300/1200\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: 23748.0581 - acc: 0.0000e+00 - val_loss: 39873.4162 - val_acc: 0.0000e+00\n",
      "Epoch 301/1200\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 24041.6294 - acc: 0.0000e+00 - val_loss: 39658.0730 - val_acc: 0.0000e+00\n",
      "Epoch 302/1200\n",
      "1137/1137 [==============================] - 0s 301us/step - loss: 24684.7655 - acc: 0.0000e+00 - val_loss: 37166.9967 - val_acc: 0.0000e+00\n",
      "Epoch 303/1200\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 24515.8499 - acc: 0.0000e+00 - val_loss: 37810.7275 - val_acc: 0.0000e+00\n",
      "Epoch 304/1200\n",
      "1137/1137 [==============================] - 0s 321us/step - loss: 23585.9633 - acc: 0.0000e+00 - val_loss: 38484.2962 - val_acc: 0.0000e+00\n",
      "Epoch 305/1200\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 24248.3741 - acc: 0.0000e+00 - val_loss: 38308.5196 - val_acc: 0.0000e+00\n",
      "Epoch 306/1200\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 24097.2734 - acc: 0.0000e+00 - val_loss: 37404.6286 - val_acc: 0.0000e+00\n",
      "Epoch 307/1200\n",
      "1137/1137 [==============================] - 0s 186us/step - loss: 24296.2416 - acc: 0.0000e+00 - val_loss: 37211.3165 - val_acc: 0.0000e+00\n",
      "Epoch 308/1200\n",
      "1137/1137 [==============================] - 0s 175us/step - loss: 23627.1522 - acc: 0.0000e+00 - val_loss: 38388.3890 - val_acc: 0.0000e+00\n",
      "Epoch 309/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 24692.7694 - acc: 0.0000e+00 - val_loss: 37876.1912 - val_acc: 0.0000e+00\n",
      "Epoch 310/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 23656.6673 - acc: 0.0000e+00 - val_loss: 38030.9316 - val_acc: 0.0000e+00\n",
      "Epoch 311/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 23388.7947 - acc: 0.0000e+00 - val_loss: 38080.9913 - val_acc: 0.0000e+00\n",
      "Epoch 312/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 24466.7025 - acc: 0.0000e+00 - val_loss: 37354.1368 - val_acc: 0.0000e+00\n",
      "Epoch 313/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 23989.9557 - acc: 0.0000e+00 - val_loss: 37833.3582 - val_acc: 0.0000e+00\n",
      "Epoch 314/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 158us/step - loss: 23668.7226 - acc: 0.0000e+00 - val_loss: 37522.2977 - val_acc: 0.0000e+00\n",
      "Epoch 315/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 23320.7148 - acc: 0.0000e+00 - val_loss: 36903.0329 - val_acc: 0.0000e+00\n",
      "Epoch 316/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 23908.8025 - acc: 0.0000e+00 - val_loss: 37154.8055 - val_acc: 0.0000e+00\n",
      "Epoch 317/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 23648.0656 - acc: 0.0000e+00 - val_loss: 39098.1025 - val_acc: 0.0000e+00\n",
      "Epoch 318/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 23465.4729 - acc: 0.0000e+00 - val_loss: 37654.1159 - val_acc: 0.0000e+00\n",
      "Epoch 319/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 23669.6380 - acc: 0.0000e+00 - val_loss: 36907.2530 - val_acc: 0.0000e+00\n",
      "Epoch 320/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 24115.9305 - acc: 0.0000e+00 - val_loss: 36897.9722 - val_acc: 0.0000e+00\n",
      "Epoch 321/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 24555.3344 - acc: 0.0000e+00 - val_loss: 36916.5488 - val_acc: 0.0000e+00\n",
      "Epoch 322/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 22951.3684 - acc: 0.0000e+00 - val_loss: 36816.6187 - val_acc: 0.0000e+00\n",
      "Epoch 323/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 23028.2900 - acc: 0.0000e+00 - val_loss: 37228.9736 - val_acc: 0.0000e+00\n",
      "Epoch 324/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 23461.7274 - acc: 0.0000e+00 - val_loss: 37899.4340 - val_acc: 0.0000e+00\n",
      "Epoch 325/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 23896.0928 - acc: 0.0000e+00 - val_loss: 37526.8853 - val_acc: 0.0000e+00\n",
      "Epoch 326/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 23623.3937 - acc: 0.0000e+00 - val_loss: 36974.9029 - val_acc: 0.0000e+00\n",
      "Epoch 327/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 23571.8799 - acc: 0.0000e+00 - val_loss: 38700.4405 - val_acc: 0.0000e+00\n",
      "Epoch 328/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 23612.9897 - acc: 0.0000e+00 - val_loss: 37997.8577 - val_acc: 0.0000e+00\n",
      "Epoch 329/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 24176.2034 - acc: 0.0000e+00 - val_loss: 36573.2487 - val_acc: 0.0000e+00\n",
      "Epoch 330/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 23400.1673 - acc: 0.0000e+00 - val_loss: 36431.7834 - val_acc: 0.0000e+00\n",
      "Epoch 331/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 23377.6498 - acc: 0.0000e+00 - val_loss: 36665.0369 - val_acc: 0.0000e+00\n",
      "Epoch 332/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 23247.9404 - acc: 0.0000e+00 - val_loss: 36331.1201 - val_acc: 0.0000e+00\n",
      "Epoch 333/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 23827.3715 - acc: 0.0000e+00 - val_loss: 37008.9955 - val_acc: 0.0000e+00\n",
      "Epoch 334/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 23505.9568 - acc: 0.0000e+00 - val_loss: 36499.4738 - val_acc: 0.0000e+00\n",
      "Epoch 335/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 24146.1520 - acc: 0.0000e+00 - val_loss: 37233.3824 - val_acc: 0.0000e+00\n",
      "Epoch 336/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 24438.6373 - acc: 0.0000e+00 - val_loss: 36490.2047 - val_acc: 0.0000e+00\n",
      "Epoch 337/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 23011.8368 - acc: 0.0000e+00 - val_loss: 36177.5297 - val_acc: 0.0000e+00\n",
      "Epoch 338/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 23217.0436 - acc: 0.0000e+00 - val_loss: 36883.0808 - val_acc: 0.0000e+00\n",
      "Epoch 339/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 23816.9287 - acc: 0.0000e+00 - val_loss: 36168.9545 - val_acc: 0.0000e+00\n",
      "Epoch 340/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 23957.0457 - acc: 0.0000e+00 - val_loss: 37734.6409 - val_acc: 0.0000e+00\n",
      "Epoch 341/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 22940.7952 - acc: 0.0000e+00 - val_loss: 37805.9875 - val_acc: 0.0000e+00\n",
      "Epoch 342/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 23172.7711 - acc: 0.0000e+00 - val_loss: 37497.6565 - val_acc: 0.0000e+00\n",
      "Epoch 343/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 22889.5874 - acc: 0.0000e+00 - val_loss: 36831.8402 - val_acc: 0.0000e+00\n",
      "Epoch 344/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 22709.6581 - acc: 0.0000e+00 - val_loss: 35571.1693 - val_acc: 0.0000e+00\n",
      "Epoch 345/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 23677.2465 - acc: 0.0000e+00 - val_loss: 37933.6464 - val_acc: 0.0000e+00\n",
      "Epoch 346/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 22836.5806 - acc: 0.0000e+00 - val_loss: 37938.4670 - val_acc: 0.0000e+00\n",
      "Epoch 347/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 22929.8948 - acc: 0.0000e+00 - val_loss: 36041.7631 - val_acc: 0.0000e+00\n",
      "Epoch 348/1200\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 23212.2035 - acc: 0.0000e+00 - val_loss: 37792.3929 - val_acc: 0.0000e+00\n",
      "Epoch 349/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 22519.6240 - acc: 0.0000e+00 - val_loss: 37547.8259 - val_acc: 0.0000e+00\n",
      "Epoch 350/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 23230.8939 - acc: 0.0000e+00 - val_loss: 36208.9956 - val_acc: 0.0000e+00\n",
      "Epoch 351/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 23679.6858 - acc: 0.0000e+00 - val_loss: 36159.0908 - val_acc: 0.0000e+00\n",
      "Epoch 352/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 22689.8323 - acc: 0.0000e+00 - val_loss: 35692.3289 - val_acc: 0.0000e+00\n",
      "Epoch 353/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 22650.1428 - acc: 0.0000e+00 - val_loss: 39075.8092 - val_acc: 0.0000e+00\n",
      "Epoch 354/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 22714.7550 - acc: 0.0000e+00 - val_loss: 36482.2230 - val_acc: 0.0000e+00\n",
      "Epoch 355/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 22655.3316 - acc: 0.0000e+00 - val_loss: 38682.7753 - val_acc: 0.0000e+00\n",
      "Epoch 356/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 23375.5885 - acc: 0.0000e+00 - val_loss: 36946.3373 - val_acc: 0.0000e+00\n",
      "Epoch 357/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 22762.8537 - acc: 0.0000e+00 - val_loss: 38343.5132 - val_acc: 0.0000e+00\n",
      "Epoch 358/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 22899.6127 - acc: 0.0000e+00 - val_loss: 38034.7318 - val_acc: 0.0000e+00\n",
      "Epoch 359/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 22479.5693 - acc: 0.0000e+00 - val_loss: 35614.1590 - val_acc: 0.0000e+00\n",
      "Epoch 360/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 22941.2669 - acc: 0.0000e+00 - val_loss: 35899.8421 - val_acc: 0.0000e+00\n",
      "Epoch 361/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 23305.7533 - acc: 0.0000e+00 - val_loss: 35282.3692 - val_acc: 0.0000e+00\n",
      "Epoch 362/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 21914.9831 - acc: 0.0000e+00 - val_loss: 34943.8810 - val_acc: 0.0000e+00\n",
      "Epoch 363/1200\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 22969.5765 - acc: 0.0000e+00 - val_loss: 35676.2915 - val_acc: 0.0000e+00\n",
      "Epoch 364/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 22805.7660 - acc: 0.0000e+00 - val_loss: 36739.0824 - val_acc: 0.0000e+00\n",
      "Epoch 365/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 22163.0201 - acc: 0.0000e+00 - val_loss: 41083.4474 - val_acc: 0.0000e+00\n",
      "Epoch 366/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 132us/step - loss: 22206.6287 - acc: 0.0000e+00 - val_loss: 37044.4707 - val_acc: 0.0035\n",
      "Epoch 367/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 22395.2990 - acc: 0.0000e+00 - val_loss: 36509.8624 - val_acc: 0.0000e+00\n",
      "Epoch 368/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 22243.4883 - acc: 0.0000e+00 - val_loss: 37370.8503 - val_acc: 0.0000e+00\n",
      "Epoch 369/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 24232.1823 - acc: 0.0000e+00 - val_loss: 35256.0196 - val_acc: 0.0000e+00\n",
      "Epoch 370/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 22032.4056 - acc: 0.0000e+00 - val_loss: 34876.5103 - val_acc: 0.0000e+00\n",
      "Epoch 371/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 22599.7323 - acc: 0.0000e+00 - val_loss: 35752.8956 - val_acc: 0.0000e+00\n",
      "Epoch 372/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 21737.4030 - acc: 0.0000e+00 - val_loss: 35783.5336 - val_acc: 0.0000e+00\n",
      "Epoch 373/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 22477.4627 - acc: 0.0000e+00 - val_loss: 37404.9312 - val_acc: 0.0000e+00\n",
      "Epoch 374/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 22198.0358 - acc: 0.0000e+00 - val_loss: 35055.5347 - val_acc: 0.0000e+00\n",
      "Epoch 375/1200\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 22275.6735 - acc: 0.0000e+00 - val_loss: 35542.7303 - val_acc: 0.0000e+00\n",
      "Epoch 376/1200\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 21742.0591 - acc: 0.0000e+0 - 0s 134us/step - loss: 21414.1980 - acc: 0.0000e+00 - val_loss: 35352.8535 - val_acc: 0.0000e+00\n",
      "Epoch 377/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 21657.6130 - acc: 0.0000e+00 - val_loss: 35427.7176 - val_acc: 0.0000e+00\n",
      "Epoch 378/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 21982.5127 - acc: 0.0000e+00 - val_loss: 36035.0479 - val_acc: 0.0000e+00\n",
      "Epoch 379/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 21777.9575 - acc: 0.0000e+00 - val_loss: 35219.7556 - val_acc: 0.0000e+00\n",
      "Epoch 380/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 22798.6462 - acc: 0.0000e+00 - val_loss: 35446.7672 - val_acc: 0.0000e+00\n",
      "Epoch 381/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 22215.7806 - acc: 0.0000e+00 - val_loss: 34352.4223 - val_acc: 0.0000e+00\n",
      "Epoch 382/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 22039.8033 - acc: 0.0000e+00 - val_loss: 34443.3358 - val_acc: 0.0000e+00\n",
      "Epoch 383/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 21910.3944 - acc: 0.0000e+00 - val_loss: 34445.6439 - val_acc: 0.0000e+00\n",
      "Epoch 384/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 21771.4497 - acc: 0.0000e+00 - val_loss: 35310.7710 - val_acc: 0.0000e+00\n",
      "Epoch 385/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 21867.0557 - acc: 0.0000e+00 - val_loss: 35836.3124 - val_acc: 0.0000e+00\n",
      "Epoch 386/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 22171.7945 - acc: 0.0000e+00 - val_loss: 35135.3465 - val_acc: 0.0000e+00\n",
      "Epoch 387/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 21738.9395 - acc: 0.0000e+00 - val_loss: 35228.2968 - val_acc: 0.0000e+00\n",
      "Epoch 388/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 21627.4921 - acc: 0.0000e+00 - val_loss: 34792.8272 - val_acc: 0.0000e+00\n",
      "Epoch 389/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 21914.0693 - acc: 0.0000e+00 - val_loss: 34752.0311 - val_acc: 0.0000e+00\n",
      "Epoch 390/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 21753.1636 - acc: 0.0000e+00 - val_loss: 34941.7622 - val_acc: 0.0000e+00\n",
      "Epoch 391/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 21515.1868 - acc: 0.0000e+00 - val_loss: 35353.5293 - val_acc: 0.0000e+00\n",
      "Epoch 392/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 22173.9524 - acc: 0.0000e+00 - val_loss: 34409.9037 - val_acc: 0.0000e+00\n",
      "Epoch 393/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 21692.3918 - acc: 0.0000e+00 - val_loss: 34661.2197 - val_acc: 0.0000e+00\n",
      "Epoch 394/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 21985.5218 - acc: 0.0000e+00 - val_loss: 36233.6181 - val_acc: 0.0000e+00\n",
      "Epoch 395/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 21542.5507 - acc: 0.0000e+00 - val_loss: 35602.9298 - val_acc: 0.0000e+00\n",
      "Epoch 396/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 22188.0841 - acc: 0.0000e+00 - val_loss: 35082.6892 - val_acc: 0.0000e+00\n",
      "Epoch 397/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 21385.6578 - acc: 0.0000e+00 - val_loss: 34176.7823 - val_acc: 0.0000e+00\n",
      "Epoch 398/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 22038.2200 - acc: 0.0000e+00 - val_loss: 35623.1601 - val_acc: 0.0000e+00\n",
      "Epoch 399/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 21618.0075 - acc: 0.0000e+00 - val_loss: 35609.8501 - val_acc: 0.0000e+00\n",
      "Epoch 400/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 22130.1900 - acc: 0.0000e+00 - val_loss: 35644.7230 - val_acc: 0.0000e+00\n",
      "Epoch 401/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 21242.1493 - acc: 0.0000e+00 - val_loss: 34621.6328 - val_acc: 0.0000e+00\n",
      "Epoch 402/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 20922.9821 - acc: 0.0000e+00 - val_loss: 34422.6328 - val_acc: 0.0000e+00\n",
      "Epoch 403/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 21310.7955 - acc: 0.0000e+00 - val_loss: 34851.0951 - val_acc: 0.0000e+00\n",
      "Epoch 404/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 21235.4010 - acc: 0.0000e+00 - val_loss: 34064.9130 - val_acc: 0.0000e+00\n",
      "Epoch 405/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 21421.4872 - acc: 0.0000e+00 - val_loss: 34205.1175 - val_acc: 0.0000e+00\n",
      "Epoch 406/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 21484.7397 - acc: 0.0000e+00 - val_loss: 36591.5013 - val_acc: 0.0000e+00\n",
      "Epoch 407/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 21797.8765 - acc: 0.0000e+00 - val_loss: 36373.9943 - val_acc: 0.0000e+00\n",
      "Epoch 408/1200\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 21500.2611 - acc: 0.0000e+00 - val_loss: 34328.0457 - val_acc: 0.0000e+00\n",
      "Epoch 409/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 20653.1272 - acc: 0.0000e+00 - val_loss: 34286.9527 - val_acc: 0.0000e+00\n",
      "Epoch 410/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 20961.4110 - acc: 0.0000e+00 - val_loss: 34653.4395 - val_acc: 0.0000e+00\n",
      "Epoch 411/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 21634.9716 - acc: 0.0000e+00 - val_loss: 34403.0622 - val_acc: 0.0000e+00\n",
      "Epoch 412/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 21167.8060 - acc: 0.0000e+00 - val_loss: 35084.1336 - val_acc: 0.0000e+00\n",
      "Epoch 413/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 21681.9028 - acc: 0.0000e+00 - val_loss: 34882.5469 - val_acc: 0.0000e+00\n",
      "Epoch 414/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 21658.5766 - acc: 0.0000e+00 - val_loss: 35596.6770 - val_acc: 0.0000e+00\n",
      "Epoch 415/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 21252.5645 - acc: 0.0000e+00 - val_loss: 35208.8864 - val_acc: 0.0000e+00\n",
      "Epoch 416/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 21023.6715 - acc: 0.0000e+00 - val_loss: 36363.3520 - val_acc: 0.0000e+00\n",
      "Epoch 417/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 20759.6448 - acc: 0.0000e+00 - val_loss: 35924.3541 - val_acc: 0.0000e+00\n",
      "Epoch 418/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 141us/step - loss: 20753.1327 - acc: 0.0000e+00 - val_loss: 34520.2780 - val_acc: 0.0000e+00\n",
      "Epoch 419/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 20827.0785 - acc: 0.0000e+00 - val_loss: 36740.6998 - val_acc: 0.0000e+00\n",
      "Epoch 420/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 20732.9481 - acc: 0.0000e+00 - val_loss: 35018.0265 - val_acc: 0.0000e+00\n",
      "Epoch 421/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 21170.7279 - acc: 0.0000e+00 - val_loss: 34820.9413 - val_acc: 0.0000e+00\n",
      "Epoch 422/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 20928.1736 - acc: 0.0000e+00 - val_loss: 33939.9027 - val_acc: 0.0000e+00\n",
      "Epoch 423/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 21153.0590 - acc: 0.0000e+00 - val_loss: 34713.4316 - val_acc: 0.0000e+00\n",
      "Epoch 424/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 21221.0468 - acc: 0.0000e+00 - val_loss: 35743.7495 - val_acc: 0.0000e+00\n",
      "Epoch 425/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 21273.7794 - acc: 0.0000e+00 - val_loss: 35221.8464 - val_acc: 0.0000e+00\n",
      "Epoch 426/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 21427.9419 - acc: 0.0000e+00 - val_loss: 34221.0338 - val_acc: 0.0000e+00\n",
      "Epoch 427/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 20580.5682 - acc: 0.0000e+00 - val_loss: 37391.4595 - val_acc: 0.0000e+00\n",
      "Epoch 428/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 21101.7856 - acc: 0.0000e+00 - val_loss: 35083.9496 - val_acc: 0.0000e+00\n",
      "Epoch 429/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 21012.6524 - acc: 0.0000e+00 - val_loss: 33687.8423 - val_acc: 0.0000e+00\n",
      "Epoch 430/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 21192.4889 - acc: 0.0000e+00 - val_loss: 35271.1322 - val_acc: 0.0000e+00\n",
      "Epoch 431/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 21637.4672 - acc: 0.0000e+00 - val_loss: 37798.3270 - val_acc: 0.0000e+00\n",
      "Epoch 432/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 20969.0644 - acc: 0.0000e+00 - val_loss: 35900.8206 - val_acc: 0.0000e+00\n",
      "Epoch 433/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 20079.6632 - acc: 0.0000e+00 - val_loss: 34719.9100 - val_acc: 0.0000e+00\n",
      "Epoch 434/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 20552.3927 - acc: 0.0000e+00 - val_loss: 34120.3547 - val_acc: 0.0000e+00\n",
      "Epoch 435/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 20495.9071 - acc: 0.0000e+00 - val_loss: 35045.7851 - val_acc: 0.0000e+00\n",
      "Epoch 436/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 19983.2720 - acc: 0.0000e+00 - val_loss: 34541.2020 - val_acc: 0.0000e+00\n",
      "Epoch 437/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 20489.3522 - acc: 0.0000e+00 - val_loss: 34290.8119 - val_acc: 0.0000e+00\n",
      "Epoch 438/1200\n",
      "1137/1137 [==============================] - 0s 131us/step - loss: 21478.1387 - acc: 0.0000e+00 - val_loss: 33994.8366 - val_acc: 0.0000e+00\n",
      "Epoch 439/1200\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 20354.9848 - acc: 0.0000e+00 - val_loss: 34053.2147 - val_acc: 0.0000e+00\n",
      "Epoch 440/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 20615.3249 - acc: 0.0000e+00 - val_loss: 34229.2547 - val_acc: 0.0000e+00\n",
      "Epoch 441/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 21382.2228 - acc: 0.0000e+00 - val_loss: 34827.0806 - val_acc: 0.0000e+00\n",
      "Epoch 442/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 20521.9347 - acc: 0.0000e+00 - val_loss: 35091.6711 - val_acc: 0.0000e+00\n",
      "Epoch 443/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 20031.1394 - acc: 0.0000e+00 - val_loss: 34255.0304 - val_acc: 0.0000e+00\n",
      "Epoch 444/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 19889.4826 - acc: 0.0000e+00 - val_loss: 34732.8519 - val_acc: 0.0000e+00\n",
      "Epoch 445/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 22553.9191 - acc: 0.0000e+00 - val_loss: 36375.1916 - val_acc: 0.0000e+00\n",
      "Epoch 446/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 20884.5760 - acc: 0.0000e+00 - val_loss: 34023.5329 - val_acc: 0.0000e+00\n",
      "Epoch 447/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 20979.7965 - acc: 0.0000e+00 - val_loss: 33954.2913 - val_acc: 0.0000e+00\n",
      "Epoch 448/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 20700.7766 - acc: 0.0000e+00 - val_loss: 34465.9542 - val_acc: 0.0000e+00\n",
      "Epoch 449/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 19941.6363 - acc: 0.0000e+00 - val_loss: 33492.5433 - val_acc: 0.0000e+00\n",
      "Epoch 450/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 21282.8699 - acc: 0.0000e+00 - val_loss: 34439.2197 - val_acc: 0.0000e+00\n",
      "Epoch 451/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 20481.6289 - acc: 0.0000e+00 - val_loss: 33914.2030 - val_acc: 0.0000e+00\n",
      "Epoch 452/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 20916.3006 - acc: 0.0000e+00 - val_loss: 33452.9628 - val_acc: 0.0000e+00\n",
      "Epoch 453/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 19761.7303 - acc: 0.0000e+00 - val_loss: 33409.5654 - val_acc: 0.0000e+00\n",
      "Epoch 454/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 20300.2364 - acc: 0.0000e+00 - val_loss: 37076.7831 - val_acc: 0.0000e+00\n",
      "Epoch 455/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 21164.1039 - acc: 0.0000e+00 - val_loss: 34082.7055 - val_acc: 0.0000e+00\n",
      "Epoch 456/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 21086.0039 - acc: 0.0000e+00 - val_loss: 34750.2643 - val_acc: 0.0000e+00\n",
      "Epoch 457/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 20563.0375 - acc: 0.0000e+00 - val_loss: 35134.4580 - val_acc: 0.0000e+00\n",
      "Epoch 458/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 21434.5664 - acc: 0.0000e+00 - val_loss: 33779.8905 - val_acc: 0.0000e+00\n",
      "Epoch 459/1200\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 20250.9808 - acc: 0.0000e+00 - val_loss: 33572.4629 - val_acc: 0.0000e+00\n",
      "Epoch 460/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 19585.1457 - acc: 0.0000e+00 - val_loss: 35942.4763 - val_acc: 0.0000e+00\n",
      "Epoch 461/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 20736.8780 - acc: 0.0000e+00 - val_loss: 33353.5952 - val_acc: 0.0000e+00\n",
      "Epoch 462/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 20605.2510 - acc: 0.0000e+00 - val_loss: 34183.8474 - val_acc: 0.0000e+00\n",
      "Epoch 463/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 19897.2108 - acc: 0.0000e+00 - val_loss: 34327.8309 - val_acc: 0.0000e+00\n",
      "Epoch 464/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 20544.0474 - acc: 0.0000e+00 - val_loss: 32991.0889 - val_acc: 0.0000e+00\n",
      "Epoch 465/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 19835.7299 - acc: 0.0000e+00 - val_loss: 33941.2031 - val_acc: 0.0000e+00\n",
      "Epoch 466/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 20190.9492 - acc: 0.0000e+00 - val_loss: 34899.8266 - val_acc: 0.0000e+00\n",
      "Epoch 467/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 20698.3676 - acc: 0.0000e+00 - val_loss: 34473.3727 - val_acc: 0.0000e+00\n",
      "Epoch 468/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 20666.9860 - acc: 0.0000e+00 - val_loss: 35306.3835 - val_acc: 0.0000e+00\n",
      "Epoch 469/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 19753.7286 - acc: 0.0000e+00 - val_loss: 33212.9163 - val_acc: 0.0000e+00\n",
      "Epoch 470/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 135us/step - loss: 20022.5783 - acc: 0.0000e+00 - val_loss: 33011.1791 - val_acc: 0.0000e+00\n",
      "Epoch 471/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 20101.6757 - acc: 0.0000e+00 - val_loss: 34743.6419 - val_acc: 0.0000e+00\n",
      "Epoch 472/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 20518.1119 - acc: 0.0000e+00 - val_loss: 33695.5898 - val_acc: 0.0000e+00\n",
      "Epoch 473/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 20471.6099 - acc: 8.7951e-04 - val_loss: 33632.0332 - val_acc: 0.0000e+00\n",
      "Epoch 474/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 19399.2636 - acc: 0.0000e+00 - val_loss: 34886.5775 - val_acc: 0.0000e+00\n",
      "Epoch 475/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 19543.3564 - acc: 0.0000e+00 - val_loss: 33524.6742 - val_acc: 0.0000e+00\n",
      "Epoch 476/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 20308.4242 - acc: 0.0000e+00 - val_loss: 33809.9961 - val_acc: 0.0000e+00\n",
      "Epoch 477/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 19764.7126 - acc: 0.0000e+00 - val_loss: 33305.2232 - val_acc: 0.0000e+00\n",
      "Epoch 478/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 20073.1018 - acc: 0.0000e+00 - val_loss: 33700.5517 - val_acc: 0.0035\n",
      "Epoch 479/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 19691.8536 - acc: 0.0000e+00 - val_loss: 35026.9669 - val_acc: 0.0000e+00\n",
      "Epoch 480/1200\n",
      "1137/1137 [==============================] - 0s 208us/step - loss: 19721.1468 - acc: 0.0000e+00 - val_loss: 33406.5115 - val_acc: 0.0000e+00\n",
      "Epoch 481/1200\n",
      "1137/1137 [==============================] - 0s 164us/step - loss: 19937.3708 - acc: 0.0000e+00 - val_loss: 35092.3527 - val_acc: 0.0000e+00\n",
      "Epoch 482/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 20556.1550 - acc: 8.7951e-04 - val_loss: 32245.3318 - val_acc: 0.0000e+00\n",
      "Epoch 483/1200\n",
      "1137/1137 [==============================] - 0s 168us/step - loss: 19609.5369 - acc: 0.0000e+00 - val_loss: 33999.3116 - val_acc: 0.0000e+00\n",
      "Epoch 484/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 19326.4234 - acc: 0.0000e+00 - val_loss: 33216.1340 - val_acc: 0.0000e+00\n",
      "Epoch 485/1200\n",
      "1137/1137 [==============================] - 0s 164us/step - loss: 19664.0055 - acc: 0.0000e+00 - val_loss: 33837.8125 - val_acc: 0.0000e+00\n",
      "Epoch 486/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 19573.8248 - acc: 0.0000e+00 - val_loss: 32988.2426 - val_acc: 0.0000e+00\n",
      "Epoch 487/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 19836.1131 - acc: 0.0000e+00 - val_loss: 33263.8300 - val_acc: 0.0000e+00\n",
      "Epoch 488/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 20671.6517 - acc: 8.7951e-04 - val_loss: 35528.4439 - val_acc: 0.0000e+00\n",
      "Epoch 489/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 19255.4548 - acc: 0.0000e+00 - val_loss: 32161.5616 - val_acc: 0.0000e+00\n",
      "Epoch 490/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 19293.0827 - acc: 0.0000e+00 - val_loss: 34309.6609 - val_acc: 0.0000e+00\n",
      "Epoch 491/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 20089.2730 - acc: 0.0000e+00 - val_loss: 33382.0186 - val_acc: 0.0000e+00\n",
      "Epoch 492/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 18929.9581 - acc: 0.0000e+00 - val_loss: 32877.7910 - val_acc: 0.0000e+00\n",
      "Epoch 493/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 21933.0339 - acc: 0.0000e+00 - val_loss: 33774.1419 - val_acc: 0.0000e+00\n",
      "Epoch 494/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 19418.0031 - acc: 0.0000e+00 - val_loss: 34351.1257 - val_acc: 0.0000e+00\n",
      "Epoch 495/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 19542.0979 - acc: 0.0000e+00 - val_loss: 33390.1034 - val_acc: 0.0000e+00\n",
      "Epoch 496/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 18969.6703 - acc: 0.0000e+00 - val_loss: 35171.8895 - val_acc: 0.0000e+00\n",
      "Epoch 497/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 19558.3235 - acc: 0.0000e+00 - val_loss: 33517.8458 - val_acc: 0.0000e+00\n",
      "Epoch 498/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 19699.6368 - acc: 0.0000e+00 - val_loss: 32987.2365 - val_acc: 0.0000e+00\n",
      "Epoch 499/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 19297.8651 - acc: 0.0000e+00 - val_loss: 32964.3545 - val_acc: 0.0000e+00\n",
      "Epoch 500/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 19640.9939 - acc: 0.0000e+00 - val_loss: 37946.2756 - val_acc: 0.0000e+00\n",
      "Epoch 501/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 19620.5534 - acc: 0.0000e+00 - val_loss: 35757.9762 - val_acc: 0.0000e+00\n",
      "Epoch 502/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 20316.9269 - acc: 0.0000e+00 - val_loss: 33432.5150 - val_acc: 0.0000e+00\n",
      "Epoch 503/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 20603.9593 - acc: 0.0000e+00 - val_loss: 32444.0878 - val_acc: 0.0000e+00\n",
      "Epoch 504/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 19555.5947 - acc: 0.0000e+00 - val_loss: 34496.8572 - val_acc: 0.0000e+00\n",
      "Epoch 505/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 19553.3946 - acc: 8.7951e-04 - val_loss: 33585.7889 - val_acc: 0.0000e+00\n",
      "Epoch 506/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 19630.0683 - acc: 0.0000e+00 - val_loss: 32475.6559 - val_acc: 0.0000e+00\n",
      "Epoch 507/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 19296.3648 - acc: 0.0000e+00 - val_loss: 32246.4640 - val_acc: 0.0000e+00\n",
      "Epoch 508/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 19918.3783 - acc: 0.0000e+00 - val_loss: 32474.8012 - val_acc: 0.0000e+00\n",
      "Epoch 509/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 19254.6362 - acc: 0.0000e+00 - val_loss: 38396.4753 - val_acc: 0.0000e+00\n",
      "Epoch 510/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 19883.0759 - acc: 0.0000e+00 - val_loss: 36606.1612 - val_acc: 0.0000e+00\n",
      "Epoch 511/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 19591.9255 - acc: 0.0000e+00 - val_loss: 32717.3809 - val_acc: 0.0000e+00\n",
      "Epoch 512/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 19246.7532 - acc: 0.0000e+00 - val_loss: 32991.9948 - val_acc: 0.0000e+00\n",
      "Epoch 513/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 19140.9883 - acc: 0.0000e+00 - val_loss: 33864.7995 - val_acc: 0.0000e+00\n",
      "Epoch 514/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 18975.4349 - acc: 0.0000e+00 - val_loss: 32444.6687 - val_acc: 0.0000e+00\n",
      "Epoch 515/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 20600.4982 - acc: 0.0000e+00 - val_loss: 33934.5992 - val_acc: 0.0000e+00\n",
      "Epoch 516/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 19410.9681 - acc: 0.0000e+00 - val_loss: 32055.7566 - val_acc: 0.0000e+00\n",
      "Epoch 517/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 19429.4618 - acc: 0.0000e+00 - val_loss: 32359.6070 - val_acc: 0.0000e+00\n",
      "Epoch 518/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 18874.7353 - acc: 0.0000e+00 - val_loss: 32053.0203 - val_acc: 0.0000e+00\n",
      "Epoch 519/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 18670.8557 - acc: 0.0000e+00 - val_loss: 33511.5949 - val_acc: 0.0000e+00\n",
      "Epoch 520/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 19166.8145 - acc: 0.0000e+00 - val_loss: 33040.7536 - val_acc: 0.0000e+00\n",
      "Epoch 521/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 19456.9946 - acc: 0.0000e+00 - val_loss: 32460.1378 - val_acc: 0.0000e+00\n",
      "Epoch 522/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 146us/step - loss: 19424.8229 - acc: 0.0000e+00 - val_loss: 32286.6188 - val_acc: 0.0000e+00\n",
      "Epoch 523/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 18787.7605 - acc: 0.0000e+00 - val_loss: 32683.0794 - val_acc: 0.0000e+00\n",
      "Epoch 524/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 18936.6223 - acc: 0.0000e+00 - val_loss: 31763.6317 - val_acc: 0.0000e+00\n",
      "Epoch 525/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 20071.7805 - acc: 0.0000e+00 - val_loss: 32414.6131 - val_acc: 0.0000e+00\n",
      "Epoch 526/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 20096.9785 - acc: 0.0000e+00 - val_loss: 33024.9958 - val_acc: 0.0000e+00\n",
      "Epoch 527/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 19546.8897 - acc: 0.0000e+00 - val_loss: 32433.2086 - val_acc: 0.0000e+00\n",
      "Epoch 528/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 18856.2759 - acc: 0.0000e+00 - val_loss: 32441.6849 - val_acc: 0.0000e+00\n",
      "Epoch 529/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 18977.9808 - acc: 0.0000e+00 - val_loss: 33195.2817 - val_acc: 0.0000e+00\n",
      "Epoch 530/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 19158.5400 - acc: 0.0000e+00 - val_loss: 34208.0436 - val_acc: 0.0000e+00\n",
      "Epoch 531/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 18959.3838 - acc: 0.0000e+00 - val_loss: 31756.1004 - val_acc: 0.0000e+00\n",
      "Epoch 532/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 19181.4365 - acc: 0.0000e+00 - val_loss: 33948.6077 - val_acc: 0.0000e+00\n",
      "Epoch 533/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 19324.7596 - acc: 0.0000e+00 - val_loss: 33137.3141 - val_acc: 0.0000e+00\n",
      "Epoch 534/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 18704.1925 - acc: 0.0000e+00 - val_loss: 33510.1529 - val_acc: 0.0000e+00\n",
      "Epoch 535/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 19363.1258 - acc: 0.0000e+00 - val_loss: 33896.4833 - val_acc: 0.0000e+00\n",
      "Epoch 536/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 18849.9661 - acc: 8.7951e-04 - val_loss: 31833.8305 - val_acc: 0.0000e+00\n",
      "Epoch 537/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 19723.7384 - acc: 0.0000e+00 - val_loss: 40907.3393 - val_acc: 0.0000e+00\n",
      "Epoch 538/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 20618.2361 - acc: 0.0000e+00 - val_loss: 32624.1965 - val_acc: 0.0000e+00\n",
      "Epoch 539/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 19788.4547 - acc: 0.0000e+00 - val_loss: 33092.9274 - val_acc: 0.0000e+00\n",
      "Epoch 540/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 18678.3139 - acc: 0.0000e+00 - val_loss: 32147.3161 - val_acc: 0.0000e+00\n",
      "Epoch 541/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 18821.1300 - acc: 0.0000e+00 - val_loss: 33867.4782 - val_acc: 0.0000e+00\n",
      "Epoch 542/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 19840.2671 - acc: 0.0000e+00 - val_loss: 34233.1853 - val_acc: 0.0000e+00\n",
      "Epoch 543/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 19104.5932 - acc: 8.7951e-04 - val_loss: 33053.5628 - val_acc: 0.0000e+00\n",
      "Epoch 544/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 18977.3198 - acc: 0.0000e+00 - val_loss: 37143.6875 - val_acc: 0.0000e+00\n",
      "Epoch 545/1200\n",
      "1137/1137 [==============================] - 0s 114us/step - loss: 19597.8508 - acc: 0.0000e+00 - val_loss: 31995.9259 - val_acc: 0.0000e+00\n",
      "Epoch 546/1200\n",
      "1137/1137 [==============================] - 0s 180us/step - loss: 18993.0156 - acc: 0.0000e+00 - val_loss: 33742.3956 - val_acc: 0.0000e+00\n",
      "Epoch 547/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 19067.9400 - acc: 0.0000e+00 - val_loss: 33119.0510 - val_acc: 0.0000e+00\n",
      "Epoch 548/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 18525.7703 - acc: 0.0000e+00 - val_loss: 32177.4674 - val_acc: 0.0000e+00\n",
      "Epoch 549/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 18699.4599 - acc: 0.0000e+00 - val_loss: 31272.5885 - val_acc: 0.0000e+00\n",
      "Epoch 550/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 20908.1959 - acc: 0.0000e+00 - val_loss: 31674.8225 - val_acc: 0.0000e+00\n",
      "Epoch 551/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 19545.1829 - acc: 0.0000e+00 - val_loss: 34647.5701 - val_acc: 0.0000e+00\n",
      "Epoch 552/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 19170.2922 - acc: 0.0000e+00 - val_loss: 34474.6480 - val_acc: 0.0000e+00\n",
      "Epoch 553/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 18977.1907 - acc: 0.0000e+00 - val_loss: 32100.0150 - val_acc: 0.0000e+00\n",
      "Epoch 554/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 19253.1508 - acc: 0.0000e+00 - val_loss: 32010.3760 - val_acc: 0.0000e+00\n",
      "Epoch 555/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 20712.8452 - acc: 0.0000e+00 - val_loss: 33402.7259 - val_acc: 0.0000e+00\n",
      "Epoch 556/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 19340.2337 - acc: 0.0000e+00 - val_loss: 31921.5940 - val_acc: 0.0000e+00\n",
      "Epoch 557/1200\n",
      "1137/1137 [==============================] - 0s 178us/step - loss: 19449.7823 - acc: 0.0000e+00 - val_loss: 31449.4721 - val_acc: 0.0000e+00\n",
      "Epoch 558/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 18877.2224 - acc: 0.0000e+00 - val_loss: 31304.8700 - val_acc: 0.0000e+00\n",
      "Epoch 559/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 19126.4566 - acc: 0.0000e+00 - val_loss: 32536.7804 - val_acc: 0.0000e+00\n",
      "Epoch 560/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 18151.9845 - acc: 0.0000e+00 - val_loss: 31645.2934 - val_acc: 0.0000e+00\n",
      "Epoch 561/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 19068.9022 - acc: 0.0000e+00 - val_loss: 32454.4684 - val_acc: 0.0000e+00\n",
      "Epoch 562/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 19253.1124 - acc: 0.0000e+00 - val_loss: 32781.6050 - val_acc: 0.0000e+00\n",
      "Epoch 563/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 18638.1413 - acc: 0.0000e+00 - val_loss: 32156.2365 - val_acc: 0.0000e+00\n",
      "Epoch 564/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 18502.1849 - acc: 0.0000e+00 - val_loss: 31893.1867 - val_acc: 0.0000e+00\n",
      "Epoch 565/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 19592.8407 - acc: 0.0000e+00 - val_loss: 31318.3022 - val_acc: 0.0000e+00\n",
      "Epoch 566/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 19261.4901 - acc: 0.0000e+00 - val_loss: 38714.8365 - val_acc: 0.0000e+00\n",
      "Epoch 567/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 19692.7517 - acc: 0.0000e+00 - val_loss: 34005.2816 - val_acc: 0.0000e+00\n",
      "Epoch 568/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 19185.5057 - acc: 0.0000e+00 - val_loss: 31373.5834 - val_acc: 0.0000e+00\n",
      "Epoch 569/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 18883.4743 - acc: 0.0000e+00 - val_loss: 31919.0448 - val_acc: 0.0000e+00\n",
      "Epoch 570/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 18944.0763 - acc: 0.0000e+00 - val_loss: 31361.4618 - val_acc: 0.0000e+00\n",
      "Epoch 571/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 18470.4719 - acc: 0.0000e+00 - val_loss: 32957.2245 - val_acc: 0.0000e+00\n",
      "Epoch 572/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 18703.9502 - acc: 0.0000e+00 - val_loss: 31767.2943 - val_acc: 0.0000e+00\n",
      "Epoch 573/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 18145.2656 - acc: 0.0000e+00 - val_loss: 32033.1141 - val_acc: 0.0000e+00\n",
      "Epoch 574/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 136us/step - loss: 18943.7017 - acc: 0.0000e+00 - val_loss: 31848.9879 - val_acc: 0.0000e+00\n",
      "Epoch 575/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 19441.6894 - acc: 0.0000e+00 - val_loss: 35915.6377 - val_acc: 0.0000e+00\n",
      "Epoch 576/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 18599.4162 - acc: 0.0000e+00 - val_loss: 33283.2199 - val_acc: 0.0000e+00\n",
      "Epoch 577/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 18499.1457 - acc: 0.0000e+00 - val_loss: 31884.1928 - val_acc: 0.0000e+00\n",
      "Epoch 578/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 18661.3535 - acc: 0.0000e+00 - val_loss: 31623.1715 - val_acc: 0.0000e+00\n",
      "Epoch 579/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 18350.7263 - acc: 0.0000e+00 - val_loss: 32041.9971 - val_acc: 0.0000e+00\n",
      "Epoch 580/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 19036.0786 - acc: 0.0000e+00 - val_loss: 32006.4213 - val_acc: 0.0000e+00\n",
      "Epoch 581/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 17672.2718 - acc: 0.0000e+00 - val_loss: 32280.8481 - val_acc: 0.0000e+00\n",
      "Epoch 582/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 18497.0303 - acc: 0.0000e+00 - val_loss: 32110.8165 - val_acc: 0.0000e+00\n",
      "Epoch 583/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 18196.1120 - acc: 0.0000e+00 - val_loss: 34880.1381 - val_acc: 0.0000e+00\n",
      "Epoch 584/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 18380.2931 - acc: 0.0000e+00 - val_loss: 31211.9410 - val_acc: 0.0000e+00\n",
      "Epoch 585/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 17718.7347 - acc: 0.0000e+00 - val_loss: 32989.4254 - val_acc: 0.0000e+00\n",
      "Epoch 586/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 18207.0089 - acc: 0.0000e+00 - val_loss: 31380.8400 - val_acc: 0.0000e+00\n",
      "Epoch 587/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 17669.7453 - acc: 0.0000e+00 - val_loss: 36014.6456 - val_acc: 0.0000e+00\n",
      "Epoch 588/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 18352.3328 - acc: 0.0000e+00 - val_loss: 31577.7338 - val_acc: 0.0000e+00\n",
      "Epoch 589/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 18425.4278 - acc: 0.0000e+00 - val_loss: 31895.1338 - val_acc: 0.0000e+00\n",
      "Epoch 590/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 18760.3213 - acc: 8.7951e-04 - val_loss: 31532.3865 - val_acc: 0.0000e+00\n",
      "Epoch 591/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 18806.3270 - acc: 0.0000e+00 - val_loss: 31350.8286 - val_acc: 0.0000e+00\n",
      "Epoch 592/1200\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 17576.7708 - acc: 0.0000e+00 - val_loss: 34383.6691 - val_acc: 0.0000e+00\n",
      "Epoch 593/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 17637.5040 - acc: 0.0000e+00 - val_loss: 32591.6879 - val_acc: 0.0000e+00\n",
      "Epoch 594/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 18418.9419 - acc: 0.0000e+00 - val_loss: 36220.5505 - val_acc: 0.0000e+00\n",
      "Epoch 595/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 19117.2668 - acc: 0.0000e+00 - val_loss: 31479.8221 - val_acc: 0.0000e+00\n",
      "Epoch 596/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 18568.8219 - acc: 8.7951e-04 - val_loss: 31802.4058 - val_acc: 0.0000e+00\n",
      "Epoch 597/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 19465.6068 - acc: 8.7951e-04 - val_loss: 31232.8610 - val_acc: 0.0000e+00\n",
      "Epoch 598/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 17617.9864 - acc: 0.0000e+00 - val_loss: 31012.1163 - val_acc: 0.0000e+00\n",
      "Epoch 599/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 18995.1045 - acc: 0.0000e+00 - val_loss: 31123.3657 - val_acc: 0.0000e+00\n",
      "Epoch 600/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 19050.9253 - acc: 0.0000e+00 - val_loss: 33556.8932 - val_acc: 0.0000e+00\n",
      "Epoch 601/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 18315.6779 - acc: 0.0000e+00 - val_loss: 31656.1481 - val_acc: 0.0000e+00\n",
      "Epoch 602/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 18691.0641 - acc: 0.0000e+00 - val_loss: 33129.0960 - val_acc: 0.0000e+00\n",
      "Epoch 603/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 18391.9285 - acc: 0.0000e+00 - val_loss: 31700.4069 - val_acc: 0.0000e+00\n",
      "Epoch 604/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 20102.2734 - acc: 0.0000e+00 - val_loss: 34332.6535 - val_acc: 0.0000e+00\n",
      "Epoch 605/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 18327.1177 - acc: 0.0000e+00 - val_loss: 32159.8345 - val_acc: 0.0000e+00\n",
      "Epoch 606/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 18403.8147 - acc: 0.0000e+00 - val_loss: 33285.8449 - val_acc: 0.0000e+00\n",
      "Epoch 607/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 19374.0420 - acc: 0.0000e+00 - val_loss: 33871.6226 - val_acc: 0.0000e+00\n",
      "Epoch 608/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 18721.2211 - acc: 0.0000e+00 - val_loss: 30908.2620 - val_acc: 0.0000e+00\n",
      "Epoch 609/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 17984.4929 - acc: 0.0000e+00 - val_loss: 32025.4489 - val_acc: 0.0000e+00\n",
      "Epoch 610/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 18836.2653 - acc: 0.0000e+00 - val_loss: 31040.8166 - val_acc: 0.0000e+00\n",
      "Epoch 611/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 18241.4134 - acc: 0.0000e+00 - val_loss: 36637.8640 - val_acc: 0.0000e+00\n",
      "Epoch 612/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 18902.9312 - acc: 0.0000e+00 - val_loss: 32701.4032 - val_acc: 0.0000e+00\n",
      "Epoch 613/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 17826.3230 - acc: 0.0000e+00 - val_loss: 31710.5857 - val_acc: 0.0000e+00\n",
      "Epoch 614/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 18652.2671 - acc: 0.0000e+00 - val_loss: 31181.2951 - val_acc: 0.0000e+00\n",
      "Epoch 615/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 18153.9095 - acc: 0.0000e+00 - val_loss: 31683.0530 - val_acc: 0.0000e+00\n",
      "Epoch 616/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 18379.4375 - acc: 0.0000e+00 - val_loss: 31115.3853 - val_acc: 0.0000e+00\n",
      "Epoch 617/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 17213.2028 - acc: 0.0000e+00 - val_loss: 30958.9019 - val_acc: 0.0000e+00\n",
      "Epoch 618/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 18679.8192 - acc: 0.0000e+00 - val_loss: 31427.0819 - val_acc: 0.0000e+00\n",
      "Epoch 619/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 17743.2744 - acc: 0.0000e+00 - val_loss: 32202.8473 - val_acc: 0.0000e+00\n",
      "Epoch 620/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 18069.1040 - acc: 0.0000e+00 - val_loss: 32067.7747 - val_acc: 0.0000e+00\n",
      "Epoch 621/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 18662.5977 - acc: 0.0000e+00 - val_loss: 32362.2563 - val_acc: 0.0000e+00\n",
      "Epoch 622/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 17364.4485 - acc: 0.0000e+00 - val_loss: 32049.5631 - val_acc: 0.0000e+00\n",
      "Epoch 623/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 17823.9824 - acc: 0.0000e+00 - val_loss: 32386.5373 - val_acc: 0.0000e+00\n",
      "Epoch 624/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 18038.3161 - acc: 0.0000e+00 - val_loss: 31914.3979 - val_acc: 0.0000e+00\n",
      "Epoch 625/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 17370.3651 - acc: 0.0000e+00 - val_loss: 31843.5596 - val_acc: 0.0000e+00\n",
      "Epoch 626/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 136us/step - loss: 18245.0093 - acc: 0.0000e+00 - val_loss: 31330.0577 - val_acc: 0.0000e+00\n",
      "Epoch 627/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 17619.6527 - acc: 0.0000e+00 - val_loss: 31895.8288 - val_acc: 0.0000e+00\n",
      "Epoch 628/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 18444.6174 - acc: 0.0000e+00 - val_loss: 33086.7626 - val_acc: 0.0000e+00\n",
      "Epoch 629/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 17806.0992 - acc: 0.0000e+00 - val_loss: 33259.9550 - val_acc: 0.0000e+00\n",
      "Epoch 630/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 17741.3437 - acc: 0.0000e+00 - val_loss: 31190.9754 - val_acc: 0.0000e+00\n",
      "Epoch 631/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 17745.9808 - acc: 0.0000e+00 - val_loss: 32558.6898 - val_acc: 0.0000e+00\n",
      "Epoch 632/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 18060.7142 - acc: 0.0000e+00 - val_loss: 30964.9313 - val_acc: 0.0000e+00\n",
      "Epoch 633/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 18314.5457 - acc: 0.0000e+00 - val_loss: 32507.6363 - val_acc: 0.0000e+00\n",
      "Epoch 634/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 17138.4863 - acc: 0.0000e+00 - val_loss: 31492.5091 - val_acc: 0.0000e+00\n",
      "Epoch 635/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 18364.4054 - acc: 0.0000e+00 - val_loss: 33342.9529 - val_acc: 0.0000e+00\n",
      "Epoch 636/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 17824.7080 - acc: 0.0000e+00 - val_loss: 30793.6813 - val_acc: 0.0000e+00\n",
      "Epoch 637/1200\n",
      "1137/1137 [==============================] - 0s 199us/step - loss: 17634.6687 - acc: 0.0000e+00 - val_loss: 30765.3699 - val_acc: 0.0000e+00\n",
      "Epoch 638/1200\n",
      "1137/1137 [==============================] - 0s 171us/step - loss: 18598.9639 - acc: 0.0000e+00 - val_loss: 30313.2758 - val_acc: 0.0000e+00\n",
      "Epoch 639/1200\n",
      "1137/1137 [==============================] - 0s 169us/step - loss: 18053.4428 - acc: 8.7951e-04 - val_loss: 35589.4094 - val_acc: 0.0035\n",
      "Epoch 640/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 18957.4462 - acc: 0.0000e+00 - val_loss: 30742.3268 - val_acc: 0.0000e+00\n",
      "Epoch 641/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 17514.0817 - acc: 0.0000e+00 - val_loss: 32275.4799 - val_acc: 0.0000e+00\n",
      "Epoch 642/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 19050.0152 - acc: 0.0000e+00 - val_loss: 32043.6778 - val_acc: 0.0000e+00\n",
      "Epoch 643/1200\n",
      "1137/1137 [==============================] - 0s 177us/step - loss: 17639.6384 - acc: 0.0000e+00 - val_loss: 30775.1643 - val_acc: 0.0000e+00\n",
      "Epoch 644/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 17773.0056 - acc: 0.0000e+00 - val_loss: 30572.1966 - val_acc: 0.0000e+00\n",
      "Epoch 645/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 17852.0920 - acc: 0.0000e+00 - val_loss: 33686.4012 - val_acc: 0.0000e+00\n",
      "Epoch 646/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 18612.8547 - acc: 0.0000e+00 - val_loss: 30804.5184 - val_acc: 0.0000e+00\n",
      "Epoch 647/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 17623.4721 - acc: 0.0000e+00 - val_loss: 31177.8357 - val_acc: 0.0000e+00\n",
      "Epoch 648/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 17823.6292 - acc: 0.0000e+00 - val_loss: 30705.2916 - val_acc: 0.0000e+00\n",
      "Epoch 649/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 17427.1081 - acc: 0.0000e+00 - val_loss: 30853.8742 - val_acc: 0.0000e+00\n",
      "Epoch 650/1200\n",
      "1137/1137 [==============================] - 0s 175us/step - loss: 18619.3868 - acc: 0.0000e+00 - val_loss: 31001.6847 - val_acc: 0.0000e+00\n",
      "Epoch 651/1200\n",
      "1137/1137 [==============================] - 0s 176us/step - loss: 17848.7775 - acc: 0.0000e+00 - val_loss: 31278.1555 - val_acc: 0.0000e+00\n",
      "Epoch 652/1200\n",
      "1137/1137 [==============================] - 0s 194us/step - loss: 17434.0269 - acc: 0.0000e+00 - val_loss: 30255.0596 - val_acc: 0.0000e+00\n",
      "Epoch 653/1200\n",
      "1137/1137 [==============================] - 0s 178us/step - loss: 17732.1354 - acc: 0.0000e+00 - val_loss: 30996.2921 - val_acc: 0.0000e+00\n",
      "Epoch 654/1200\n",
      "1137/1137 [==============================] - 0s 164us/step - loss: 17092.1612 - acc: 0.0000e+00 - val_loss: 30551.4260 - val_acc: 0.0000e+00\n",
      "Epoch 655/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 17551.9598 - acc: 0.0000e+00 - val_loss: 30704.6783 - val_acc: 0.0000e+00\n",
      "Epoch 656/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 17873.7923 - acc: 0.0000e+00 - val_loss: 31247.3418 - val_acc: 0.0000e+00\n",
      "Epoch 657/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 18412.5482 - acc: 0.0000e+00 - val_loss: 31054.6907 - val_acc: 0.0000e+00\n",
      "Epoch 658/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 18158.3354 - acc: 0.0000e+00 - val_loss: 30273.6133 - val_acc: 0.0000e+00\n",
      "Epoch 659/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 18537.3017 - acc: 0.0000e+00 - val_loss: 30843.8866 - val_acc: 0.0000e+00\n",
      "Epoch 660/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 17995.8241 - acc: 0.0000e+00 - val_loss: 32523.8095 - val_acc: 0.0000e+00\n",
      "Epoch 661/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 17455.1346 - acc: 0.0000e+00 - val_loss: 31002.6132 - val_acc: 0.0000e+00\n",
      "Epoch 662/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 18289.7485 - acc: 0.0000e+00 - val_loss: 31321.2378 - val_acc: 0.0000e+00\n",
      "Epoch 663/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 17157.2505 - acc: 0.0000e+00 - val_loss: 31299.1783 - val_acc: 0.0000e+00\n",
      "Epoch 664/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 17378.6150 - acc: 0.0000e+00 - val_loss: 30391.2526 - val_acc: 0.0000e+00\n",
      "Epoch 665/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 17500.5442 - acc: 0.0000e+00 - val_loss: 30544.2730 - val_acc: 0.0000e+00\n",
      "Epoch 666/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 16936.2058 - acc: 0.0000e+00 - val_loss: 30791.7591 - val_acc: 0.0000e+00\n",
      "Epoch 667/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 16844.7642 - acc: 0.0000e+00 - val_loss: 31885.7148 - val_acc: 0.0000e+00\n",
      "Epoch 668/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 17914.4939 - acc: 0.0000e+00 - val_loss: 32185.8455 - val_acc: 0.0000e+00\n",
      "Epoch 669/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 17590.0172 - acc: 0.0000e+00 - val_loss: 31088.2884 - val_acc: 0.0000e+00\n",
      "Epoch 670/1200\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 16543.0473 - acc: 0.0000e+00 - val_loss: 31029.7539 - val_acc: 0.0000e+00\n",
      "Epoch 671/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 17648.3601 - acc: 0.0000e+00 - val_loss: 33346.5833 - val_acc: 0.0000e+00\n",
      "Epoch 672/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 17812.8082 - acc: 0.0000e+00 - val_loss: 30280.0360 - val_acc: 0.0000e+00\n",
      "Epoch 673/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 17416.4664 - acc: 0.0000e+00 - val_loss: 30631.3816 - val_acc: 0.0000e+00\n",
      "Epoch 674/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 17715.0866 - acc: 0.0000e+00 - val_loss: 31650.9062 - val_acc: 0.0000e+00\n",
      "Epoch 675/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 17904.5178 - acc: 0.0000e+00 - val_loss: 31087.4312 - val_acc: 0.0000e+00\n",
      "Epoch 676/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 17250.5893 - acc: 0.0000e+00 - val_loss: 32624.1043 - val_acc: 0.0000e+00\n",
      "Epoch 677/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 16843.6277 - acc: 0.0000e+00 - val_loss: 30930.9453 - val_acc: 0.0000e+00\n",
      "Epoch 678/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 137us/step - loss: 17598.6747 - acc: 0.0000e+00 - val_loss: 30392.7840 - val_acc: 0.0000e+00\n",
      "Epoch 679/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 17316.2445 - acc: 0.0000e+00 - val_loss: 29932.5524 - val_acc: 0.0000e+00\n",
      "Epoch 680/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 16569.9061 - acc: 0.0000e+00 - val_loss: 31383.4779 - val_acc: 0.0000e+00\n",
      "Epoch 681/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 17450.0483 - acc: 0.0000e+00 - val_loss: 32152.3710 - val_acc: 0.0000e+00\n",
      "Epoch 682/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 16829.3549 - acc: 0.0000e+00 - val_loss: 31349.2888 - val_acc: 0.0000e+00\n",
      "Epoch 683/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 17222.1200 - acc: 0.0000e+00 - val_loss: 32909.3307 - val_acc: 0.0000e+00\n",
      "Epoch 684/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 17260.8342 - acc: 0.0000e+00 - val_loss: 31430.7022 - val_acc: 0.0000e+00\n",
      "Epoch 685/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 17307.2304 - acc: 0.0000e+00 - val_loss: 32548.7299 - val_acc: 0.0000e+00\n",
      "Epoch 686/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 17910.3854 - acc: 0.0000e+00 - val_loss: 34326.2668 - val_acc: 0.0000e+00\n",
      "Epoch 687/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 17677.9175 - acc: 0.0000e+00 - val_loss: 34010.3065 - val_acc: 0.0000e+00\n",
      "Epoch 688/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 17127.7453 - acc: 0.0000e+00 - val_loss: 31106.2045 - val_acc: 0.0000e+00\n",
      "Epoch 689/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 16844.5123 - acc: 0.0000e+00 - val_loss: 31804.1587 - val_acc: 0.0000e+00\n",
      "Epoch 690/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 17621.9056 - acc: 0.0000e+00 - val_loss: 31503.7155 - val_acc: 0.0000e+00\n",
      "Epoch 691/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 17166.5416 - acc: 0.0000e+00 - val_loss: 31826.1463 - val_acc: 0.0000e+00\n",
      "Epoch 692/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 17105.2674 - acc: 0.0000e+00 - val_loss: 31324.0515 - val_acc: 0.0000e+00\n",
      "Epoch 693/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 17811.6391 - acc: 0.0000e+00 - val_loss: 30246.5053 - val_acc: 0.0000e+00\n",
      "Epoch 694/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 17193.8295 - acc: 0.0000e+00 - val_loss: 30910.2641 - val_acc: 0.0000e+00\n",
      "Epoch 695/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 17983.4040 - acc: 0.0000e+00 - val_loss: 34518.3665 - val_acc: 0.0000e+00\n",
      "Epoch 696/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 17885.5741 - acc: 0.0000e+00 - val_loss: 29938.4332 - val_acc: 0.0000e+00\n",
      "Epoch 697/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 17129.6147 - acc: 0.0000e+00 - val_loss: 30779.7643 - val_acc: 0.0000e+00\n",
      "Epoch 698/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 17411.8242 - acc: 0.0000e+00 - val_loss: 31254.7334 - val_acc: 0.0000e+00\n",
      "Epoch 699/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 17171.9548 - acc: 0.0000e+00 - val_loss: 30359.6600 - val_acc: 0.0000e+00\n",
      "Epoch 700/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 17220.9039 - acc: 0.0000e+00 - val_loss: 31632.5156 - val_acc: 0.0000e+00\n",
      "Epoch 701/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 16998.0922 - acc: 0.0000e+00 - val_loss: 33402.7659 - val_acc: 0.0000e+00\n",
      "Epoch 702/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 16430.3673 - acc: 0.0000e+00 - val_loss: 29235.7321 - val_acc: 0.0000e+00\n",
      "Epoch 703/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 16902.1605 - acc: 8.7951e-04 - val_loss: 30425.9713 - val_acc: 0.0000e+00\n",
      "Epoch 704/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 17396.5379 - acc: 0.0000e+00 - val_loss: 30224.8219 - val_acc: 0.0000e+00\n",
      "Epoch 705/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 16995.7033 - acc: 0.0000e+00 - val_loss: 30352.1926 - val_acc: 0.0000e+00\n",
      "Epoch 706/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 16619.8750 - acc: 0.0000e+00 - val_loss: 32071.9142 - val_acc: 0.0000e+00\n",
      "Epoch 707/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 17252.7709 - acc: 0.0000e+00 - val_loss: 32184.1602 - val_acc: 0.0000e+00\n",
      "Epoch 708/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 16866.5486 - acc: 0.0000e+00 - val_loss: 30584.6086 - val_acc: 0.0000e+00\n",
      "Epoch 709/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 16799.9150 - acc: 0.0000e+00 - val_loss: 29732.1626 - val_acc: 0.0000e+00\n",
      "Epoch 710/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 16254.2481 - acc: 0.0000e+00 - val_loss: 30758.1438 - val_acc: 0.0000e+00\n",
      "Epoch 711/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 17212.3159 - acc: 0.0000e+00 - val_loss: 30486.3530 - val_acc: 0.0000e+00\n",
      "Epoch 712/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 17366.0061 - acc: 0.0000e+00 - val_loss: 38856.1741 - val_acc: 0.0000e+00\n",
      "Epoch 713/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 17409.5969 - acc: 0.0000e+00 - val_loss: 30582.9368 - val_acc: 0.0000e+00\n",
      "Epoch 714/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 16488.3790 - acc: 0.0000e+00 - val_loss: 29676.6837 - val_acc: 0.0000e+00\n",
      "Epoch 715/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 17721.8130 - acc: 0.0000e+00 - val_loss: 31624.5127 - val_acc: 0.0000e+00\n",
      "Epoch 716/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 17187.3977 - acc: 0.0000e+00 - val_loss: 30424.9437 - val_acc: 0.0000e+00\n",
      "Epoch 717/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 16393.1617 - acc: 0.0000e+00 - val_loss: 30140.6893 - val_acc: 0.0000e+00\n",
      "Epoch 718/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 16351.5839 - acc: 0.0000e+00 - val_loss: 31572.9912 - val_acc: 0.0000e+00\n",
      "Epoch 719/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 16802.5961 - acc: 0.0000e+00 - val_loss: 31383.4103 - val_acc: 0.0000e+00\n",
      "Epoch 720/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 17178.4012 - acc: 0.0000e+00 - val_loss: 31129.2227 - val_acc: 0.0000e+00\n",
      "Epoch 721/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 18704.7538 - acc: 0.0000e+00 - val_loss: 30312.0447 - val_acc: 0.0000e+00\n",
      "Epoch 722/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 16948.9884 - acc: 0.0000e+00 - val_loss: 30288.7011 - val_acc: 0.0000e+00\n",
      "Epoch 723/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 16354.0285 - acc: 0.0000e+00 - val_loss: 31412.5724 - val_acc: 0.0000e+00\n",
      "Epoch 724/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 16163.6327 - acc: 0.0000e+00 - val_loss: 30045.6597 - val_acc: 0.0000e+00\n",
      "Epoch 725/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 17122.1686 - acc: 0.0000e+00 - val_loss: 30076.1417 - val_acc: 0.0000e+00\n",
      "Epoch 726/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 17339.5734 - acc: 0.0000e+00 - val_loss: 29644.3924 - val_acc: 0.0035\n",
      "Epoch 727/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 17414.8653 - acc: 0.0000e+00 - val_loss: 29756.0565 - val_acc: 0.0000e+00\n",
      "Epoch 728/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 16794.7958 - acc: 0.0000e+00 - val_loss: 30887.6057 - val_acc: 0.0000e+00\n",
      "Epoch 729/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 16727.6303 - acc: 0.0000e+00 - val_loss: 30131.6255 - val_acc: 0.0000e+00\n",
      "Epoch 730/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 144us/step - loss: 15949.4591 - acc: 0.0000e+00 - val_loss: 30655.2640 - val_acc: 0.0000e+00\n",
      "Epoch 731/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 17215.2716 - acc: 0.0000e+00 - val_loss: 32288.2649 - val_acc: 0.0000e+00\n",
      "Epoch 732/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 16646.2483 - acc: 0.0000e+00 - val_loss: 38406.5675 - val_acc: 0.0000e+00\n",
      "Epoch 733/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 17660.1874 - acc: 0.0000e+00 - val_loss: 30218.7027 - val_acc: 0.0000e+00\n",
      "Epoch 734/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 17042.8990 - acc: 0.0000e+00 - val_loss: 32182.2693 - val_acc: 0.0000e+00\n",
      "Epoch 735/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 17361.9343 - acc: 0.0000e+00 - val_loss: 30609.0487 - val_acc: 0.0000e+00\n",
      "Epoch 736/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 15844.3397 - acc: 0.0000e+00 - val_loss: 30872.3349 - val_acc: 0.0000e+00\n",
      "Epoch 737/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 17363.5985 - acc: 8.7951e-04 - val_loss: 30977.7152 - val_acc: 0.0000e+00\n",
      "Epoch 738/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 17156.5490 - acc: 0.0000e+00 - val_loss: 31097.2504 - val_acc: 0.0000e+00\n",
      "Epoch 739/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 17544.5785 - acc: 0.0000e+00 - val_loss: 29730.7136 - val_acc: 0.0000e+00\n",
      "Epoch 740/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 16162.5620 - acc: 0.0000e+00 - val_loss: 29088.0030 - val_acc: 0.0000e+00\n",
      "Epoch 741/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 16865.0325 - acc: 0.0000e+00 - val_loss: 30359.7313 - val_acc: 0.0000e+00\n",
      "Epoch 742/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 16238.4298 - acc: 0.0000e+00 - val_loss: 29180.0470 - val_acc: 0.0000e+00\n",
      "Epoch 743/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 16436.8135 - acc: 0.0000e+00 - val_loss: 31015.5265 - val_acc: 0.0000e+00\n",
      "Epoch 744/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 16151.6347 - acc: 8.7951e-04 - val_loss: 30274.1509 - val_acc: 0.0000e+00\n",
      "Epoch 745/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 16627.6123 - acc: 0.0000e+00 - val_loss: 30323.1045 - val_acc: 0.0000e+00\n",
      "Epoch 746/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 16525.1540 - acc: 0.0000e+00 - val_loss: 29963.0783 - val_acc: 0.0000e+00\n",
      "Epoch 747/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 16520.7268 - acc: 0.0000e+00 - val_loss: 31514.1369 - val_acc: 0.0000e+00\n",
      "Epoch 748/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 17120.1302 - acc: 0.0000e+00 - val_loss: 29772.1781 - val_acc: 0.0000e+00\n",
      "Epoch 749/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 15601.5759 - acc: 8.7951e-04 - val_loss: 30102.8162 - val_acc: 0.0000e+00\n",
      "Epoch 750/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 16606.5944 - acc: 0.0000e+00 - val_loss: 29973.9860 - val_acc: 0.0000e+00\n",
      "Epoch 751/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 16763.6401 - acc: 0.0000e+00 - val_loss: 29371.2938 - val_acc: 0.0000e+00\n",
      "Epoch 752/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 16297.0019 - acc: 0.0000e+00 - val_loss: 32013.2660 - val_acc: 0.0000e+00\n",
      "Epoch 753/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 16326.4331 - acc: 0.0000e+00 - val_loss: 30495.0056 - val_acc: 0.0000e+00\n",
      "Epoch 754/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 16637.8755 - acc: 0.0000e+00 - val_loss: 30333.9534 - val_acc: 0.0000e+00\n",
      "Epoch 755/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 16289.4760 - acc: 0.0000e+00 - val_loss: 30502.4419 - val_acc: 0.0000e+00\n",
      "Epoch 756/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 16049.7384 - acc: 0.0000e+00 - val_loss: 30244.5055 - val_acc: 0.0000e+00\n",
      "Epoch 757/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 16214.3275 - acc: 0.0000e+00 - val_loss: 29730.2308 - val_acc: 0.0000e+00\n",
      "Epoch 758/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 16105.7414 - acc: 0.0000e+00 - val_loss: 29749.6314 - val_acc: 0.0000e+00\n",
      "Epoch 759/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 16517.0766 - acc: 0.0000e+00 - val_loss: 30159.1972 - val_acc: 0.0000e+00\n",
      "Epoch 760/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 16343.8983 - acc: 0.0000e+00 - val_loss: 29416.6222 - val_acc: 0.0000e+00\n",
      "Epoch 761/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 16216.8878 - acc: 0.0000e+00 - val_loss: 30127.9521 - val_acc: 0.0000e+00\n",
      "Epoch 762/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 16508.5186 - acc: 0.0000e+00 - val_loss: 30589.2313 - val_acc: 0.0000e+00\n",
      "Epoch 763/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 16961.4149 - acc: 0.0000e+00 - val_loss: 31680.8139 - val_acc: 0.0000e+00\n",
      "Epoch 764/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 17328.3540 - acc: 0.0000e+00 - val_loss: 30381.5554 - val_acc: 0.0000e+00\n",
      "Epoch 765/1200\n",
      "1137/1137 [==============================] - 0s 162us/step - loss: 15876.9721 - acc: 0.0000e+00 - val_loss: 29160.5464 - val_acc: 0.0000e+00\n",
      "Epoch 766/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 16244.9217 - acc: 0.0000e+00 - val_loss: 29065.9826 - val_acc: 0.0000e+00\n",
      "Epoch 767/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 15683.6824 - acc: 0.0000e+00 - val_loss: 30044.7327 - val_acc: 0.0000e+00\n",
      "Epoch 768/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 16159.8306 - acc: 0.0000e+00 - val_loss: 31302.7537 - val_acc: 0.0000e+00\n",
      "Epoch 769/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 16181.8775 - acc: 0.0000e+00 - val_loss: 29279.9154 - val_acc: 0.0000e+00\n",
      "Epoch 770/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 16496.0610 - acc: 0.0000e+00 - val_loss: 29799.9279 - val_acc: 0.0000e+00\n",
      "Epoch 771/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 17178.7933 - acc: 0.0000e+00 - val_loss: 30177.0726 - val_acc: 0.0000e+00\n",
      "Epoch 772/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 16668.7889 - acc: 0.0000e+00 - val_loss: 30121.0881 - val_acc: 0.0000e+00\n",
      "Epoch 773/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 15588.4607 - acc: 0.0000e+00 - val_loss: 28813.2343 - val_acc: 0.0000e+00\n",
      "Epoch 774/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 16539.7642 - acc: 0.0000e+00 - val_loss: 30297.8599 - val_acc: 0.0000e+00\n",
      "Epoch 775/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 15530.0919 - acc: 0.0000e+00 - val_loss: 30078.3014 - val_acc: 0.0000e+00\n",
      "Epoch 776/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 16378.3864 - acc: 0.0000e+00 - val_loss: 28725.6082 - val_acc: 0.0000e+00\n",
      "Epoch 777/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 16004.5938 - acc: 0.0000e+00 - val_loss: 29771.7876 - val_acc: 0.0000e+00\n",
      "Epoch 778/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 16146.9820 - acc: 0.0000e+00 - val_loss: 28449.9453 - val_acc: 0.0000e+00\n",
      "Epoch 779/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15268.2715 - acc: 0.0000e+00 - val_loss: 29493.5250 - val_acc: 0.0000e+00\n",
      "Epoch 780/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 15944.7362 - acc: 0.0000e+00 - val_loss: 31208.4170 - val_acc: 0.0000e+00\n",
      "Epoch 781/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 15805.9753 - acc: 0.0000e+00 - val_loss: 28705.7329 - val_acc: 0.0000e+00\n",
      "Epoch 782/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 150us/step - loss: 15827.8180 - acc: 0.0000e+00 - val_loss: 29249.9822 - val_acc: 0.0000e+00\n",
      "Epoch 783/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 15656.1995 - acc: 0.0000e+00 - val_loss: 35619.2314 - val_acc: 0.0000e+00\n",
      "Epoch 784/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 16516.3597 - acc: 0.0000e+00 - val_loss: 30054.0699 - val_acc: 0.0000e+00\n",
      "Epoch 785/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 17302.6245 - acc: 0.0000e+00 - val_loss: 30278.1868 - val_acc: 0.0000e+00\n",
      "Epoch 786/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 16056.2955 - acc: 8.7951e-04 - val_loss: 30617.9379 - val_acc: 0.0000e+00\n",
      "Epoch 787/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 17043.9291 - acc: 0.0000e+00 - val_loss: 30485.5697 - val_acc: 0.0000e+00\n",
      "Epoch 788/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 16585.3640 - acc: 0.0000e+00 - val_loss: 29802.2152 - val_acc: 0.0000e+00\n",
      "Epoch 789/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15597.3847 - acc: 0.0000e+00 - val_loss: 28853.2575 - val_acc: 0.0000e+00\n",
      "Epoch 790/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 16428.6900 - acc: 0.0000e+00 - val_loss: 29532.6348 - val_acc: 0.0000e+00\n",
      "Epoch 791/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 16682.7699 - acc: 0.0000e+00 - val_loss: 28481.7287 - val_acc: 0.0000e+00\n",
      "Epoch 792/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 16374.2832 - acc: 0.0000e+00 - val_loss: 29682.5170 - val_acc: 0.0000e+00\n",
      "Epoch 793/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 15628.6409 - acc: 0.0000e+00 - val_loss: 30222.3767 - val_acc: 0.0000e+00\n",
      "Epoch 794/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 16022.7373 - acc: 0.0000e+00 - val_loss: 31476.7516 - val_acc: 0.0000e+00\n",
      "Epoch 795/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 16268.9931 - acc: 0.0000e+00 - val_loss: 28850.1365 - val_acc: 0.0000e+00\n",
      "Epoch 796/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 15282.7172 - acc: 0.0000e+00 - val_loss: 30528.0284 - val_acc: 0.0000e+00\n",
      "Epoch 797/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 15876.6673 - acc: 0.0000e+00 - val_loss: 32313.0825 - val_acc: 0.0000e+00\n",
      "Epoch 798/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 16456.4473 - acc: 0.0000e+00 - val_loss: 30728.0934 - val_acc: 0.0000e+00\n",
      "Epoch 799/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 15638.3529 - acc: 0.0000e+00 - val_loss: 29679.8801 - val_acc: 0.0000e+00\n",
      "Epoch 800/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15877.1788 - acc: 0.0000e+00 - val_loss: 28699.0674 - val_acc: 0.0000e+00\n",
      "Epoch 801/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 16310.3182 - acc: 0.0000e+00 - val_loss: 33747.5796 - val_acc: 0.0000e+00\n",
      "Epoch 802/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 16447.3916 - acc: 0.0000e+00 - val_loss: 28835.7685 - val_acc: 0.0000e+00\n",
      "Epoch 803/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 15391.3829 - acc: 0.0000e+00 - val_loss: 29839.8526 - val_acc: 0.0000e+00\n",
      "Epoch 804/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 16377.2834 - acc: 0.0000e+00 - val_loss: 33294.9408 - val_acc: 0.0000e+00\n",
      "Epoch 805/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 15980.7853 - acc: 0.0000e+00 - val_loss: 28888.8484 - val_acc: 0.0000e+00\n",
      "Epoch 806/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14953.6747 - acc: 0.0000e+00 - val_loss: 28673.0845 - val_acc: 0.0000e+00\n",
      "Epoch 807/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 15694.2566 - acc: 0.0000e+00 - val_loss: 28947.8874 - val_acc: 0.0000e+00\n",
      "Epoch 808/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 15949.1519 - acc: 0.0000e+00 - val_loss: 29128.5880 - val_acc: 0.0000e+00\n",
      "Epoch 809/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 15035.1270 - acc: 0.0000e+00 - val_loss: 30317.9098 - val_acc: 0.0000e+00\n",
      "Epoch 810/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 15223.2111 - acc: 0.0000e+00 - val_loss: 31871.2477 - val_acc: 0.0000e+00\n",
      "Epoch 811/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 15608.2782 - acc: 0.0000e+00 - val_loss: 29037.2900 - val_acc: 0.0000e+00\n",
      "Epoch 812/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 16390.8142 - acc: 0.0000e+00 - val_loss: 28406.9513 - val_acc: 0.0000e+00\n",
      "Epoch 813/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 16145.6907 - acc: 0.0000e+00 - val_loss: 29378.7887 - val_acc: 0.0000e+00\n",
      "Epoch 814/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 17216.3156 - acc: 0.0000e+00 - val_loss: 28397.7631 - val_acc: 0.0000e+00\n",
      "Epoch 815/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 15411.1879 - acc: 0.0000e+00 - val_loss: 29806.7684 - val_acc: 0.0000e+00\n",
      "Epoch 816/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 15208.8312 - acc: 0.0000e+00 - val_loss: 28993.1617 - val_acc: 0.0000e+00\n",
      "Epoch 817/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 15551.1632 - acc: 0.0000e+00 - val_loss: 30301.5492 - val_acc: 0.0000e+00\n",
      "Epoch 818/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 15036.2724 - acc: 0.0000e+00 - val_loss: 28894.2605 - val_acc: 0.0000e+00\n",
      "Epoch 819/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 15329.3578 - acc: 0.0000e+00 - val_loss: 28895.7332 - val_acc: 0.0000e+00\n",
      "Epoch 820/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 15479.4766 - acc: 0.0000e+00 - val_loss: 29273.5552 - val_acc: 0.0000e+00\n",
      "Epoch 821/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 15672.6316 - acc: 0.0000e+00 - val_loss: 28640.5715 - val_acc: 0.0000e+00\n",
      "Epoch 822/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 15355.7818 - acc: 0.0000e+00 - val_loss: 28656.0170 - val_acc: 0.0000e+00\n",
      "Epoch 823/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 15622.4011 - acc: 8.7951e-04 - val_loss: 29757.1398 - val_acc: 0.0000e+00\n",
      "Epoch 824/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 17012.3554 - acc: 0.0000e+00 - val_loss: 29657.4447 - val_acc: 0.0000e+00\n",
      "Epoch 825/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 15698.7503 - acc: 0.0000e+00 - val_loss: 28390.4670 - val_acc: 0.0000e+00\n",
      "Epoch 826/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 15067.2015 - acc: 0.0000e+00 - val_loss: 29435.6994 - val_acc: 0.0000e+00\n",
      "Epoch 827/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 15803.0568 - acc: 0.0000e+00 - val_loss: 31049.3737 - val_acc: 0.0000e+00\n",
      "Epoch 828/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 15205.9796 - acc: 0.0000e+00 - val_loss: 29405.9480 - val_acc: 0.0000e+00\n",
      "Epoch 829/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 16267.5168 - acc: 0.0000e+00 - val_loss: 28719.9784 - val_acc: 0.0000e+00\n",
      "Epoch 830/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 15584.8974 - acc: 0.0000e+00 - val_loss: 29899.4298 - val_acc: 0.0000e+00\n",
      "Epoch 831/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 15151.0796 - acc: 0.0000e+00 - val_loss: 29087.6743 - val_acc: 0.0000e+00\n",
      "Epoch 832/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 16391.3601 - acc: 8.7951e-04 - val_loss: 29105.3307 - val_acc: 0.0000e+00\n",
      "Epoch 833/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 16110.6278 - acc: 0.0000e+00 - val_loss: 29824.0333 - val_acc: 0.0000e+00\n",
      "Epoch 834/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 155us/step - loss: 16106.0668 - acc: 0.0000e+00 - val_loss: 31556.6068 - val_acc: 0.0000e+00\n",
      "Epoch 835/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 16430.3910 - acc: 0.0000e+00 - val_loss: 28473.2263 - val_acc: 0.0000e+00\n",
      "Epoch 836/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 15797.1370 - acc: 8.7951e-04 - val_loss: 29503.0418 - val_acc: 0.0000e+00\n",
      "Epoch 837/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 16120.0188 - acc: 0.0000e+00 - val_loss: 28652.7686 - val_acc: 0.0000e+00\n",
      "Epoch 838/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 16004.9279 - acc: 0.0000e+00 - val_loss: 28994.3481 - val_acc: 0.0000e+00\n",
      "Epoch 839/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 15485.3905 - acc: 0.0000e+00 - val_loss: 30488.4788 - val_acc: 0.0000e+00\n",
      "Epoch 840/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 16638.6023 - acc: 0.0000e+00 - val_loss: 29125.0711 - val_acc: 0.0000e+00\n",
      "Epoch 841/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 14748.5082 - acc: 0.0000e+00 - val_loss: 29099.4553 - val_acc: 0.0000e+00\n",
      "Epoch 842/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 15717.9238 - acc: 0.0000e+00 - val_loss: 28562.0006 - val_acc: 0.0000e+00\n",
      "Epoch 843/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 15473.6602 - acc: 0.0000e+00 - val_loss: 28820.9265 - val_acc: 0.0000e+00\n",
      "Epoch 844/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 14998.4731 - acc: 0.0000e+00 - val_loss: 29082.7386 - val_acc: 0.0000e+00\n",
      "Epoch 845/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 15991.9351 - acc: 0.0000e+00 - val_loss: 28513.9941 - val_acc: 0.0000e+00\n",
      "Epoch 846/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 14721.5785 - acc: 0.0000e+00 - val_loss: 28829.1218 - val_acc: 0.0000e+00\n",
      "Epoch 847/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 15493.5329 - acc: 0.0000e+00 - val_loss: 28824.5356 - val_acc: 0.0000e+00\n",
      "Epoch 848/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 14996.4650 - acc: 0.0000e+00 - val_loss: 29788.7941 - val_acc: 0.0000e+00\n",
      "Epoch 849/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 15706.3605 - acc: 0.0000e+00 - val_loss: 28860.7812 - val_acc: 0.0000e+00\n",
      "Epoch 850/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 15024.7351 - acc: 0.0000e+00 - val_loss: 28830.2482 - val_acc: 0.0000e+00\n",
      "Epoch 851/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 16157.0335 - acc: 0.0000e+00 - val_loss: 29232.3439 - val_acc: 0.0000e+00\n",
      "Epoch 852/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 15465.2616 - acc: 0.0000e+00 - val_loss: 29141.8287 - val_acc: 0.0000e+00\n",
      "Epoch 853/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15588.2942 - acc: 0.0000e+00 - val_loss: 28740.7195 - val_acc: 0.0000e+00\n",
      "Epoch 854/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15671.6016 - acc: 0.0000e+00 - val_loss: 30006.5252 - val_acc: 0.0000e+00\n",
      "Epoch 855/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 15695.0523 - acc: 0.0000e+00 - val_loss: 31268.9494 - val_acc: 0.0000e+00\n",
      "Epoch 856/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15727.2409 - acc: 0.0000e+00 - val_loss: 31103.1873 - val_acc: 0.0000e+00\n",
      "Epoch 857/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 16424.9425 - acc: 0.0000e+00 - val_loss: 28379.3685 - val_acc: 0.0000e+00\n",
      "Epoch 858/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 15312.7756 - acc: 0.0000e+00 - val_loss: 29380.7210 - val_acc: 0.0000e+00\n",
      "Epoch 859/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 15366.1166 - acc: 0.0000e+00 - val_loss: 29923.6399 - val_acc: 0.0000e+00\n",
      "Epoch 860/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14966.7540 - acc: 0.0000e+00 - val_loss: 30343.7788 - val_acc: 0.0000e+00\n",
      "Epoch 861/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 16325.6356 - acc: 0.0000e+00 - val_loss: 29168.0966 - val_acc: 0.0000e+00\n",
      "Epoch 862/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15350.4558 - acc: 0.0000e+00 - val_loss: 28541.8467 - val_acc: 0.0000e+00\n",
      "Epoch 863/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 15220.5629 - acc: 0.0000e+00 - val_loss: 29833.3848 - val_acc: 0.0000e+00\n",
      "Epoch 864/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 14635.0873 - acc: 0.0000e+00 - val_loss: 30251.0904 - val_acc: 0.0000e+00\n",
      "Epoch 865/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 14995.5559 - acc: 0.0000e+00 - val_loss: 29216.7384 - val_acc: 0.0000e+00\n",
      "Epoch 866/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 14583.8322 - acc: 0.0000e+00 - val_loss: 33575.5238 - val_acc: 0.0000e+00\n",
      "Epoch 867/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 15346.9819 - acc: 0.0000e+00 - val_loss: 29492.7951 - val_acc: 0.0000e+00\n",
      "Epoch 868/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 15270.6228 - acc: 0.0000e+00 - val_loss: 29460.3921 - val_acc: 0.0000e+00\n",
      "Epoch 869/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 15354.9929 - acc: 0.0000e+00 - val_loss: 29755.9066 - val_acc: 0.0000e+00\n",
      "Epoch 870/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 15029.7438 - acc: 0.0000e+00 - val_loss: 29451.2261 - val_acc: 0.0000e+00\n",
      "Epoch 871/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 15342.3441 - acc: 0.0000e+00 - val_loss: 29611.9409 - val_acc: 0.0000e+00\n",
      "Epoch 872/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15787.9528 - acc: 0.0000e+00 - val_loss: 30689.8565 - val_acc: 0.0000e+00\n",
      "Epoch 873/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 15047.0155 - acc: 0.0000e+00 - val_loss: 29961.8985 - val_acc: 0.0000e+00\n",
      "Epoch 874/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14474.9619 - acc: 0.0000e+00 - val_loss: 30947.6716 - val_acc: 0.0000e+00\n",
      "Epoch 875/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 16306.5660 - acc: 0.0000e+00 - val_loss: 29286.2162 - val_acc: 0.0000e+00\n",
      "Epoch 876/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 15147.7179 - acc: 0.0000e+00 - val_loss: 30069.6554 - val_acc: 0.0000e+00\n",
      "Epoch 877/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 15127.9365 - acc: 0.0000e+00 - val_loss: 30372.8579 - val_acc: 0.0000e+00\n",
      "Epoch 878/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14374.2107 - acc: 0.0000e+00 - val_loss: 29746.4667 - val_acc: 0.0000e+00\n",
      "Epoch 879/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 15131.4300 - acc: 0.0000e+00 - val_loss: 29129.5240 - val_acc: 0.0000e+00\n",
      "Epoch 880/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 14555.8556 - acc: 0.0000e+00 - val_loss: 29280.0559 - val_acc: 0.0000e+00\n",
      "Epoch 881/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 15625.3047 - acc: 0.0000e+00 - val_loss: 30071.6302 - val_acc: 0.0000e+00\n",
      "Epoch 882/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 15740.7672 - acc: 0.0000e+00 - val_loss: 30965.6950 - val_acc: 0.0000e+00\n",
      "Epoch 883/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 14738.1174 - acc: 0.0000e+00 - val_loss: 30261.8455 - val_acc: 0.0000e+00\n",
      "Epoch 884/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 15111.4441 - acc: 0.0000e+00 - val_loss: 29018.6777 - val_acc: 0.0000e+00\n",
      "Epoch 885/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 15400.4263 - acc: 0.0000e+00 - val_loss: 29574.9524 - val_acc: 0.0000e+00\n",
      "Epoch 886/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 144us/step - loss: 15755.6812 - acc: 0.0000e+00 - val_loss: 30946.5010 - val_acc: 0.0000e+00\n",
      "Epoch 887/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 15015.6564 - acc: 0.0000e+00 - val_loss: 29343.7306 - val_acc: 0.0000e+00\n",
      "Epoch 888/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14968.3342 - acc: 0.0000e+00 - val_loss: 29457.8245 - val_acc: 0.0000e+00\n",
      "Epoch 889/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 15593.0634 - acc: 0.0000e+00 - val_loss: 30242.1984 - val_acc: 0.0000e+00\n",
      "Epoch 890/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 14860.3934 - acc: 0.0000e+00 - val_loss: 29403.2456 - val_acc: 0.0000e+00\n",
      "Epoch 891/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 15803.0758 - acc: 0.0000e+00 - val_loss: 29701.6864 - val_acc: 0.0000e+00\n",
      "Epoch 892/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 14962.5966 - acc: 8.7951e-04 - val_loss: 30510.0711 - val_acc: 0.0000e+00\n",
      "Epoch 893/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 15973.1300 - acc: 0.0000e+00 - val_loss: 36611.3739 - val_acc: 0.0000e+00\n",
      "Epoch 894/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 15134.0285 - acc: 0.0000e+00 - val_loss: 29145.7079 - val_acc: 0.0000e+00\n",
      "Epoch 895/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 15580.1876 - acc: 0.0000e+00 - val_loss: 33478.1608 - val_acc: 0.0000e+00\n",
      "Epoch 896/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 16140.4059 - acc: 0.0000e+00 - val_loss: 32520.9482 - val_acc: 0.0000e+00\n",
      "Epoch 897/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 15895.6791 - acc: 0.0000e+00 - val_loss: 29769.3698 - val_acc: 0.0000e+00\n",
      "Epoch 898/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 16546.4749 - acc: 0.0000e+00 - val_loss: 30760.8305 - val_acc: 0.0000e+00\n",
      "Epoch 899/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14761.3030 - acc: 8.7951e-04 - val_loss: 29724.8031 - val_acc: 0.0000e+00\n",
      "Epoch 900/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 15831.6164 - acc: 0.0000e+00 - val_loss: 30101.4837 - val_acc: 0.0000e+00\n",
      "Epoch 901/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 14855.5040 - acc: 0.0000e+00 - val_loss: 29245.5003 - val_acc: 0.0000e+00\n",
      "Epoch 902/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14589.0317 - acc: 0.0000e+00 - val_loss: 30412.5019 - val_acc: 0.0000e+00\n",
      "Epoch 903/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 15197.3347 - acc: 0.0000e+00 - val_loss: 29177.6673 - val_acc: 0.0000e+00\n",
      "Epoch 904/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 16254.2969 - acc: 0.0000e+00 - val_loss: 28946.5767 - val_acc: 0.0000e+00\n",
      "Epoch 905/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 14604.9838 - acc: 8.7951e-04 - val_loss: 28849.8714 - val_acc: 0.0000e+00\n",
      "Epoch 906/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 14342.7098 - acc: 0.0000e+00 - val_loss: 29575.7444 - val_acc: 0.0000e+00\n",
      "Epoch 907/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 15405.2899 - acc: 0.0000e+00 - val_loss: 29794.5128 - val_acc: 0.0000e+00\n",
      "Epoch 908/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14972.8956 - acc: 0.0000e+00 - val_loss: 28293.1809 - val_acc: 0.0000e+00\n",
      "Epoch 909/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14472.1653 - acc: 0.0000e+00 - val_loss: 28600.7165 - val_acc: 0.0000e+00\n",
      "Epoch 910/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 15029.7020 - acc: 0.0000e+00 - val_loss: 28853.2741 - val_acc: 0.0000e+00\n",
      "Epoch 911/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15270.4856 - acc: 0.0000e+00 - val_loss: 29807.0576 - val_acc: 0.0000e+00\n",
      "Epoch 912/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14888.7236 - acc: 0.0000e+00 - val_loss: 30173.4603 - val_acc: 0.0000e+00\n",
      "Epoch 913/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 15586.5767 - acc: 0.0000e+00 - val_loss: 30126.0573 - val_acc: 0.0000e+00\n",
      "Epoch 914/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 14720.8406 - acc: 0.0000e+00 - val_loss: 30267.6239 - val_acc: 0.0000e+00\n",
      "Epoch 915/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 15184.4519 - acc: 0.0000e+00 - val_loss: 29505.3265 - val_acc: 0.0000e+00\n",
      "Epoch 916/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 14767.3820 - acc: 0.0000e+00 - val_loss: 29139.3571 - val_acc: 0.0000e+00\n",
      "Epoch 917/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 14993.9534 - acc: 0.0000e+00 - val_loss: 29710.9957 - val_acc: 0.0000e+00\n",
      "Epoch 918/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 14982.2626 - acc: 0.0000e+00 - val_loss: 28973.6331 - val_acc: 0.0000e+00\n",
      "Epoch 919/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14740.2653 - acc: 0.0000e+00 - val_loss: 28346.1602 - val_acc: 0.0000e+00\n",
      "Epoch 920/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14491.5914 - acc: 0.0000e+00 - val_loss: 29571.4167 - val_acc: 0.0000e+00\n",
      "Epoch 921/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14288.6912 - acc: 8.7951e-04 - val_loss: 31086.4133 - val_acc: 0.0000e+00\n",
      "Epoch 922/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 14982.9271 - acc: 0.0000e+00 - val_loss: 29103.1733 - val_acc: 0.0000e+00\n",
      "Epoch 923/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14089.8043 - acc: 0.0000e+00 - val_loss: 30186.2535 - val_acc: 0.0000e+00\n",
      "Epoch 924/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 15024.8468 - acc: 0.0000e+00 - val_loss: 30835.6597 - val_acc: 0.0000e+00\n",
      "Epoch 925/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 14661.1776 - acc: 0.0000e+00 - val_loss: 29870.4253 - val_acc: 0.0000e+00\n",
      "Epoch 926/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14007.1435 - acc: 0.0000e+00 - val_loss: 30718.8310 - val_acc: 0.0000e+00\n",
      "Epoch 927/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 14843.5561 - acc: 8.7951e-04 - val_loss: 29758.3007 - val_acc: 0.0000e+00\n",
      "Epoch 928/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 14430.8002 - acc: 0.0000e+00 - val_loss: 30951.6582 - val_acc: 0.0000e+00\n",
      "Epoch 929/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 14337.3983 - acc: 0.0000e+00 - val_loss: 30360.7664 - val_acc: 0.0000e+00\n",
      "Epoch 930/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 15220.0618 - acc: 0.0000e+00 - val_loss: 29033.0364 - val_acc: 0.0000e+00\n",
      "Epoch 931/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 14844.4933 - acc: 0.0000e+00 - val_loss: 29092.1428 - val_acc: 0.0000e+00\n",
      "Epoch 932/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 14618.8646 - acc: 0.0000e+00 - val_loss: 30242.7561 - val_acc: 0.0000e+00\n",
      "Epoch 933/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 14847.7423 - acc: 0.0000e+00 - val_loss: 29701.3743 - val_acc: 0.0000e+00\n",
      "Epoch 934/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 14243.2488 - acc: 0.0000e+00 - val_loss: 30050.6657 - val_acc: 0.0000e+00\n",
      "Epoch 935/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 15069.8779 - acc: 0.0000e+00 - val_loss: 29834.3893 - val_acc: 0.0000e+00\n",
      "Epoch 936/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 14199.0352 - acc: 0.0000e+00 - val_loss: 29599.7766 - val_acc: 0.0000e+00\n",
      "Epoch 937/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14667.8426 - acc: 0.0000e+00 - val_loss: 30386.6171 - val_acc: 0.0000e+00\n",
      "Epoch 938/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 137us/step - loss: 14243.8395 - acc: 0.0000e+00 - val_loss: 29299.3063 - val_acc: 0.0000e+00\n",
      "Epoch 939/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14992.9759 - acc: 0.0000e+00 - val_loss: 30450.8855 - val_acc: 0.0000e+00\n",
      "Epoch 940/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 14252.2705 - acc: 0.0000e+00 - val_loss: 32765.0777 - val_acc: 0.0000e+00\n",
      "Epoch 941/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 14878.5741 - acc: 0.0000e+00 - val_loss: 30900.1938 - val_acc: 0.0000e+00\n",
      "Epoch 942/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 14408.9685 - acc: 0.0000e+00 - val_loss: 32366.1892 - val_acc: 0.0000e+00\n",
      "Epoch 943/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 14358.0591 - acc: 0.0000e+00 - val_loss: 29878.7597 - val_acc: 0.0000e+00\n",
      "Epoch 944/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 14710.4815 - acc: 0.0000e+00 - val_loss: 29403.1108 - val_acc: 0.0000e+00\n",
      "Epoch 945/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 14403.8306 - acc: 0.0000e+00 - val_loss: 29039.0265 - val_acc: 0.0000e+00\n",
      "Epoch 946/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 14730.8211 - acc: 0.0000e+00 - val_loss: 30202.4333 - val_acc: 0.0000e+00\n",
      "Epoch 947/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14481.8200 - acc: 0.0000e+00 - val_loss: 29674.8720 - val_acc: 0.0000e+00\n",
      "Epoch 948/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 15110.7071 - acc: 0.0000e+00 - val_loss: 32077.8029 - val_acc: 0.0000e+00\n",
      "Epoch 949/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14509.1429 - acc: 0.0000e+00 - val_loss: 30224.5620 - val_acc: 0.0000e+00\n",
      "Epoch 950/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 14866.0568 - acc: 0.0000e+00 - val_loss: 29498.0597 - val_acc: 0.0000e+00\n",
      "Epoch 951/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14909.7805 - acc: 0.0000e+00 - val_loss: 30876.6371 - val_acc: 0.0000e+00\n",
      "Epoch 952/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 15399.7359 - acc: 0.0000e+00 - val_loss: 29958.3538 - val_acc: 0.0000e+00\n",
      "Epoch 953/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14289.7544 - acc: 0.0000e+00 - val_loss: 29732.6372 - val_acc: 0.0000e+00\n",
      "Epoch 954/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13898.9146 - acc: 0.0000e+00 - val_loss: 29980.2902 - val_acc: 0.0000e+00\n",
      "Epoch 955/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 15229.1885 - acc: 0.0000e+00 - val_loss: 30576.8081 - val_acc: 0.0000e+00\n",
      "Epoch 956/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 14858.5548 - acc: 0.0000e+00 - val_loss: 29643.5590 - val_acc: 0.0000e+00\n",
      "Epoch 957/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 15320.1271 - acc: 0.0000e+00 - val_loss: 29665.2148 - val_acc: 0.0000e+00\n",
      "Epoch 958/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 14759.7514 - acc: 0.0000e+00 - val_loss: 29910.1026 - val_acc: 0.0000e+00\n",
      "Epoch 959/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 15156.3149 - acc: 0.0000e+00 - val_loss: 31202.3740 - val_acc: 0.0000e+00\n",
      "Epoch 960/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 15540.0651 - acc: 0.0000e+00 - val_loss: 30467.0132 - val_acc: 0.0000e+00\n",
      "Epoch 961/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 14679.0094 - acc: 0.0000e+00 - val_loss: 28813.4314 - val_acc: 0.0000e+00\n",
      "Epoch 962/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 15352.0095 - acc: 0.0000e+00 - val_loss: 30550.2153 - val_acc: 0.0000e+00\n",
      "Epoch 963/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 15418.5250 - acc: 0.0000e+00 - val_loss: 28980.4325 - val_acc: 0.0000e+00\n",
      "Epoch 964/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14559.2845 - acc: 0.0000e+00 - val_loss: 30465.8162 - val_acc: 0.0000e+00\n",
      "Epoch 965/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 14246.3506 - acc: 0.0000e+00 - val_loss: 30406.6588 - val_acc: 0.0000e+00\n",
      "Epoch 966/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14040.7517 - acc: 0.0000e+00 - val_loss: 29741.4894 - val_acc: 0.0000e+00\n",
      "Epoch 967/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 14564.5694 - acc: 0.0000e+00 - val_loss: 34207.9719 - val_acc: 0.0000e+00\n",
      "Epoch 968/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 15322.7125 - acc: 0.0000e+00 - val_loss: 31076.7846 - val_acc: 0.0000e+00\n",
      "Epoch 969/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14155.3171 - acc: 0.0000e+00 - val_loss: 30392.8706 - val_acc: 0.0000e+00\n",
      "Epoch 970/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 14037.7320 - acc: 0.0000e+00 - val_loss: 29911.0406 - val_acc: 0.0000e+00\n",
      "Epoch 971/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14408.0366 - acc: 0.0000e+00 - val_loss: 28550.9180 - val_acc: 0.0000e+00\n",
      "Epoch 972/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 15019.9804 - acc: 0.0000e+00 - val_loss: 33488.2531 - val_acc: 0.0000e+00\n",
      "Epoch 973/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14022.6775 - acc: 0.0000e+00 - val_loss: 30623.3365 - val_acc: 0.0000e+00\n",
      "Epoch 974/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 15308.1091 - acc: 0.0000e+00 - val_loss: 31451.6929 - val_acc: 0.0000e+00\n",
      "Epoch 975/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15128.8969 - acc: 0.0000e+00 - val_loss: 29490.2760 - val_acc: 0.0000e+00\n",
      "Epoch 976/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 14301.0936 - acc: 0.0000e+00 - val_loss: 29287.8706 - val_acc: 0.0000e+00\n",
      "Epoch 977/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14807.1147 - acc: 0.0000e+00 - val_loss: 30689.3696 - val_acc: 0.0000e+00\n",
      "Epoch 978/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14289.6167 - acc: 0.0000e+00 - val_loss: 29836.1021 - val_acc: 0.0000e+00\n",
      "Epoch 979/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 14267.7734 - acc: 0.0000e+00 - val_loss: 29955.8681 - val_acc: 0.0000e+00\n",
      "Epoch 980/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 14285.8909 - acc: 0.0000e+00 - val_loss: 29229.7056 - val_acc: 0.0000e+00\n",
      "Epoch 981/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 13900.0811 - acc: 0.0000e+00 - val_loss: 31023.8696 - val_acc: 0.0000e+00\n",
      "Epoch 982/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14089.0490 - acc: 0.0000e+00 - val_loss: 30426.9391 - val_acc: 0.0000e+00\n",
      "Epoch 983/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 13620.5712 - acc: 0.0000e+00 - val_loss: 28785.4515 - val_acc: 0.0000e+00\n",
      "Epoch 984/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14426.1687 - acc: 0.0000e+00 - val_loss: 29287.4457 - val_acc: 0.0000e+00\n",
      "Epoch 985/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 13844.8401 - acc: 0.0000e+00 - val_loss: 29662.9005 - val_acc: 0.0000e+00\n",
      "Epoch 986/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14305.5190 - acc: 0.0000e+00 - val_loss: 29637.0822 - val_acc: 0.0000e+00\n",
      "Epoch 987/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 14552.6794 - acc: 0.0000e+00 - val_loss: 30578.8611 - val_acc: 0.0000e+00\n",
      "Epoch 988/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 15163.5737 - acc: 0.0000e+00 - val_loss: 29655.3501 - val_acc: 0.0000e+00\n",
      "Epoch 989/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 13736.7743 - acc: 0.0000e+00 - val_loss: 30720.1774 - val_acc: 0.0000e+00\n",
      "Epoch 990/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 143us/step - loss: 14392.2491 - acc: 0.0000e+00 - val_loss: 29941.1426 - val_acc: 0.0000e+00\n",
      "Epoch 991/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 13861.9774 - acc: 0.0000e+00 - val_loss: 29818.7009 - val_acc: 0.0000e+00\n",
      "Epoch 992/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 14869.9156 - acc: 0.0000e+00 - val_loss: 29685.3956 - val_acc: 0.0000e+00\n",
      "Epoch 993/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14791.4860 - acc: 0.0000e+00 - val_loss: 29894.3283 - val_acc: 0.0000e+00\n",
      "Epoch 994/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 13911.9092 - acc: 0.0000e+00 - val_loss: 32144.8549 - val_acc: 0.0000e+00\n",
      "Epoch 995/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 14655.9831 - acc: 0.0000e+00 - val_loss: 30736.1206 - val_acc: 0.0000e+00\n",
      "Epoch 996/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 14952.8528 - acc: 0.0000e+00 - val_loss: 31305.2434 - val_acc: 0.0000e+00\n",
      "Epoch 997/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 14400.5879 - acc: 0.0000e+00 - val_loss: 30908.7987 - val_acc: 0.0000e+00\n",
      "Epoch 998/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 15246.4547 - acc: 0.0000e+00 - val_loss: 29081.5224 - val_acc: 0.0000e+00\n",
      "Epoch 999/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14159.8178 - acc: 0.0000e+00 - val_loss: 30021.1275 - val_acc: 0.0000e+00\n",
      "Epoch 1000/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 14272.3862 - acc: 0.0000e+00 - val_loss: 33298.6239 - val_acc: 0.0000e+00\n",
      "Epoch 1001/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 15156.9131 - acc: 0.0000e+00 - val_loss: 31285.1405 - val_acc: 0.0000e+00\n",
      "Epoch 1002/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 14560.0978 - acc: 0.0000e+00 - val_loss: 29569.7031 - val_acc: 0.0000e+00\n",
      "Epoch 1003/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 14166.4471 - acc: 0.0000e+00 - val_loss: 29467.0858 - val_acc: 0.0000e+00\n",
      "Epoch 1004/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 15247.8036 - acc: 0.0000e+00 - val_loss: 30314.8302 - val_acc: 0.0000e+00\n",
      "Epoch 1005/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 13879.3022 - acc: 0.0000e+00 - val_loss: 30056.9854 - val_acc: 0.0000e+00\n",
      "Epoch 1006/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14041.3565 - acc: 0.0000e+00 - val_loss: 30496.7625 - val_acc: 0.0000e+00\n",
      "Epoch 1007/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 13950.7124 - acc: 0.0000e+00 - val_loss: 30698.0621 - val_acc: 0.0000e+00\n",
      "Epoch 1008/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 15584.2007 - acc: 0.0000e+00 - val_loss: 29550.1702 - val_acc: 0.0000e+00\n",
      "Epoch 1009/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 14066.0637 - acc: 0.0000e+00 - val_loss: 29941.9596 - val_acc: 0.0035\n",
      "Epoch 1010/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 13795.4201 - acc: 8.7951e-04 - val_loss: 31111.7795 - val_acc: 0.0000e+00\n",
      "Epoch 1011/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 14372.2428 - acc: 8.7951e-04 - val_loss: 31178.4102 - val_acc: 0.0000e+00\n",
      "Epoch 1012/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14550.9352 - acc: 0.0000e+00 - val_loss: 31771.0518 - val_acc: 0.0000e+00\n",
      "Epoch 1013/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 14124.8743 - acc: 0.0000e+00 - val_loss: 29847.9082 - val_acc: 0.0000e+00\n",
      "Epoch 1014/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14463.3749 - acc: 0.0000e+00 - val_loss: 30544.9513 - val_acc: 0.0000e+00\n",
      "Epoch 1015/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 14434.9115 - acc: 0.0000e+00 - val_loss: 30748.2976 - val_acc: 0.0000e+00\n",
      "Epoch 1016/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 14925.1704 - acc: 0.0000e+00 - val_loss: 30222.6794 - val_acc: 0.0000e+00\n",
      "Epoch 1017/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14613.1771 - acc: 0.0000e+00 - val_loss: 30306.7809 - val_acc: 0.0000e+00\n",
      "Epoch 1018/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14571.7942 - acc: 0.0000e+00 - val_loss: 29640.3158 - val_acc: 0.0000e+00\n",
      "Epoch 1019/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15452.7077 - acc: 0.0000e+00 - val_loss: 31876.6182 - val_acc: 0.0000e+00\n",
      "Epoch 1020/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 14419.2981 - acc: 0.0000e+00 - val_loss: 29433.4353 - val_acc: 0.0000e+00\n",
      "Epoch 1021/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 14004.6422 - acc: 0.0000e+00 - val_loss: 29820.5047 - val_acc: 0.0000e+00\n",
      "Epoch 1022/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14499.7684 - acc: 0.0000e+00 - val_loss: 30249.3157 - val_acc: 0.0000e+00\n",
      "Epoch 1023/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14296.2428 - acc: 0.0000e+00 - val_loss: 29250.5516 - val_acc: 0.0000e+00\n",
      "Epoch 1024/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 13454.8722 - acc: 0.0000e+00 - val_loss: 29940.1150 - val_acc: 0.0000e+00\n",
      "Epoch 1025/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13689.0204 - acc: 0.0000e+00 - val_loss: 29944.0093 - val_acc: 0.0000e+00\n",
      "Epoch 1026/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 14397.5310 - acc: 0.0000e+00 - val_loss: 34500.7702 - val_acc: 0.0000e+00\n",
      "Epoch 1027/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 14569.5025 - acc: 0.0000e+00 - val_loss: 29732.1251 - val_acc: 0.0000e+00\n",
      "Epoch 1028/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13801.0352 - acc: 0.0000e+00 - val_loss: 29930.6793 - val_acc: 0.0000e+00\n",
      "Epoch 1029/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 13506.3325 - acc: 0.0000e+00 - val_loss: 30495.2424 - val_acc: 0.0000e+00\n",
      "Epoch 1030/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 13806.0714 - acc: 0.0000e+00 - val_loss: 29972.5575 - val_acc: 0.0000e+00\n",
      "Epoch 1031/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14055.4563 - acc: 8.7951e-04 - val_loss: 29213.5015 - val_acc: 0.0000e+00\n",
      "Epoch 1032/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 14684.5363 - acc: 0.0000e+00 - val_loss: 29852.8262 - val_acc: 0.0000e+00\n",
      "Epoch 1033/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 14314.1124 - acc: 0.0000e+00 - val_loss: 29416.8422 - val_acc: 0.0000e+00\n",
      "Epoch 1034/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14613.5579 - acc: 0.0000e+00 - val_loss: 29239.7673 - val_acc: 0.0000e+00\n",
      "Epoch 1035/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14859.3564 - acc: 0.0000e+00 - val_loss: 29383.7006 - val_acc: 0.0000e+00\n",
      "Epoch 1036/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 13294.0362 - acc: 0.0000e+00 - val_loss: 29884.1531 - val_acc: 0.0000e+00\n",
      "Epoch 1037/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 14308.7505 - acc: 0.0000e+00 - val_loss: 30678.2031 - val_acc: 0.0000e+00\n",
      "Epoch 1038/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 14892.5729 - acc: 0.0000e+00 - val_loss: 29572.9197 - val_acc: 0.0000e+00\n",
      "Epoch 1039/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14841.8904 - acc: 0.0000e+00 - val_loss: 29575.8726 - val_acc: 0.0000e+00\n",
      "Epoch 1040/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 13653.6020 - acc: 0.0000e+00 - val_loss: 29875.9316 - val_acc: 0.0000e+00\n",
      "Epoch 1041/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 15108.2828 - acc: 0.0000e+00 - val_loss: 30037.4026 - val_acc: 0.0000e+00\n",
      "Epoch 1042/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 137us/step - loss: 13920.6126 - acc: 0.0000e+00 - val_loss: 31059.2053 - val_acc: 0.0000e+00\n",
      "Epoch 1043/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 13492.9792 - acc: 0.0000e+00 - val_loss: 30712.2940 - val_acc: 0.0000e+00\n",
      "Epoch 1044/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 13987.4520 - acc: 0.0000e+00 - val_loss: 30201.5731 - val_acc: 0.0000e+00\n",
      "Epoch 1045/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14940.7762 - acc: 0.0000e+00 - val_loss: 29487.7764 - val_acc: 0.0000e+00\n",
      "Epoch 1046/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 13504.0920 - acc: 0.0000e+00 - val_loss: 31184.4606 - val_acc: 0.0000e+00\n",
      "Epoch 1047/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14220.9032 - acc: 0.0000e+00 - val_loss: 30124.0270 - val_acc: 0.0000e+00\n",
      "Epoch 1048/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 14761.9208 - acc: 0.0000e+00 - val_loss: 31205.9042 - val_acc: 0.0000e+00\n",
      "Epoch 1049/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 13522.1662 - acc: 0.0000e+00 - val_loss: 30797.1589 - val_acc: 0.0000e+00\n",
      "Epoch 1050/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 14389.9632 - acc: 0.0000e+00 - val_loss: 30224.9415 - val_acc: 0.0000e+00\n",
      "Epoch 1051/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 14445.9824 - acc: 0.0000e+00 - val_loss: 30884.2482 - val_acc: 0.0000e+00\n",
      "Epoch 1052/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 13712.4397 - acc: 0.0000e+00 - val_loss: 30447.6062 - val_acc: 0.0000e+00\n",
      "Epoch 1053/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14431.0283 - acc: 0.0000e+00 - val_loss: 30779.1432 - val_acc: 0.0000e+00\n",
      "Epoch 1054/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13873.2849 - acc: 0.0000e+00 - val_loss: 29254.9071 - val_acc: 0.0000e+00\n",
      "Epoch 1055/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14573.1140 - acc: 0.0000e+00 - val_loss: 30437.5611 - val_acc: 0.0000e+00\n",
      "Epoch 1056/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 13724.4531 - acc: 0.0000e+00 - val_loss: 34939.3668 - val_acc: 0.0000e+00\n",
      "Epoch 1057/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 14050.0952 - acc: 0.0000e+00 - val_loss: 30549.0538 - val_acc: 0.0000e+00\n",
      "Epoch 1058/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 14940.9319 - acc: 0.0000e+00 - val_loss: 31434.9913 - val_acc: 0.0000e+00\n",
      "Epoch 1059/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 14604.6474 - acc: 0.0000e+00 - val_loss: 31833.2829 - val_acc: 0.0000e+00\n",
      "Epoch 1060/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14059.4739 - acc: 0.0000e+00 - val_loss: 30489.5207 - val_acc: 0.0000e+00\n",
      "Epoch 1061/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 14362.3230 - acc: 0.0000e+00 - val_loss: 29874.4910 - val_acc: 0.0000e+00\n",
      "Epoch 1062/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13755.0780 - acc: 0.0000e+00 - val_loss: 29584.6772 - val_acc: 0.0000e+00\n",
      "Epoch 1063/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 13694.3671 - acc: 0.0000e+00 - val_loss: 30470.0853 - val_acc: 0.0000e+00\n",
      "Epoch 1064/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 13466.0215 - acc: 0.0000e+00 - val_loss: 31211.3786 - val_acc: 0.0000e+00\n",
      "Epoch 1065/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 14095.5693 - acc: 0.0000e+00 - val_loss: 30520.0873 - val_acc: 0.0000e+00\n",
      "Epoch 1066/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14675.1325 - acc: 0.0000e+00 - val_loss: 30083.7754 - val_acc: 0.0000e+00\n",
      "Epoch 1067/1200\n",
      "1137/1137 [==============================] - 0s 134us/step - loss: 13759.9476 - acc: 0.0000e+00 - val_loss: 30481.8807 - val_acc: 0.0000e+00\n",
      "Epoch 1068/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 14187.6602 - acc: 0.0000e+00 - val_loss: 28940.6830 - val_acc: 0.0000e+00\n",
      "Epoch 1069/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 14460.3534 - acc: 0.0000e+00 - val_loss: 30659.6643 - val_acc: 0.0000e+00\n",
      "Epoch 1070/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 14096.4246 - acc: 0.0000e+00 - val_loss: 29983.1755 - val_acc: 0.0000e+00\n",
      "Epoch 1071/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 14644.8539 - acc: 0.0000e+00 - val_loss: 30657.6019 - val_acc: 0.0000e+00\n",
      "Epoch 1072/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 13501.5236 - acc: 0.0000e+00 - val_loss: 30763.6839 - val_acc: 0.0000e+00\n",
      "Epoch 1073/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 15218.8482 - acc: 0.0000e+00 - val_loss: 30971.5939 - val_acc: 0.0000e+00\n",
      "Epoch 1074/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 13641.0572 - acc: 0.0000e+00 - val_loss: 28792.0434 - val_acc: 0.0000e+00\n",
      "Epoch 1075/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 14071.5110 - acc: 0.0000e+00 - val_loss: 29802.8030 - val_acc: 0.0000e+00\n",
      "Epoch 1076/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 13465.9123 - acc: 8.7951e-04 - val_loss: 30144.1865 - val_acc: 0.0000e+00\n",
      "Epoch 1077/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 14018.4886 - acc: 0.0000e+00 - val_loss: 30073.0848 - val_acc: 0.0000e+00\n",
      "Epoch 1078/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13753.7138 - acc: 0.0000e+00 - val_loss: 33637.1930 - val_acc: 0.0000e+00\n",
      "Epoch 1079/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 14733.1366 - acc: 0.0000e+00 - val_loss: 30387.3870 - val_acc: 0.0000e+00\n",
      "Epoch 1080/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13705.2551 - acc: 0.0000e+00 - val_loss: 30822.2596 - val_acc: 0.0000e+00\n",
      "Epoch 1081/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 13749.8071 - acc: 0.0000e+00 - val_loss: 31012.8454 - val_acc: 0.0000e+00\n",
      "Epoch 1082/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 14724.4489 - acc: 0.0000e+00 - val_loss: 30363.0321 - val_acc: 0.0000e+00\n",
      "Epoch 1083/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 13807.6544 - acc: 0.0000e+00 - val_loss: 30869.4865 - val_acc: 0.0000e+00\n",
      "Epoch 1084/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 13884.3751 - acc: 0.0000e+00 - val_loss: 32127.7268 - val_acc: 0.0000e+00\n",
      "Epoch 1085/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 14237.9403 - acc: 0.0000e+00 - val_loss: 31897.6952 - val_acc: 0.0000e+00\n",
      "Epoch 1086/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 14351.8280 - acc: 0.0000e+00 - val_loss: 31667.1607 - val_acc: 0.0000e+00\n",
      "Epoch 1087/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14148.9611 - acc: 0.0000e+00 - val_loss: 30881.3125 - val_acc: 0.0000e+00\n",
      "Epoch 1088/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 15207.5358 - acc: 0.0000e+00 - val_loss: 29930.9918 - val_acc: 0.0035\n",
      "Epoch 1089/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 15209.7381 - acc: 0.0000e+00 - val_loss: 30005.0673 - val_acc: 0.0000e+00\n",
      "Epoch 1090/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 13954.8541 - acc: 0.0000e+00 - val_loss: 30471.5426 - val_acc: 0.0000e+00\n",
      "Epoch 1091/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13689.8158 - acc: 0.0000e+00 - val_loss: 30974.4344 - val_acc: 0.0000e+00\n",
      "Epoch 1092/1200\n",
      "1137/1137 [==============================] - 0s 136us/step - loss: 14815.8253 - acc: 0.0000e+00 - val_loss: 30018.7143 - val_acc: 0.0000e+00\n",
      "Epoch 1093/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 16107.2438 - acc: 0.0000e+00 - val_loss: 30007.2710 - val_acc: 0.0000e+00\n",
      "Epoch 1094/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 143us/step - loss: 14041.4341 - acc: 8.7951e-04 - val_loss: 30371.7279 - val_acc: 0.0000e+00\n",
      "Epoch 1095/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13903.9414 - acc: 0.0000e+00 - val_loss: 30807.7361 - val_acc: 0.0000e+00\n",
      "Epoch 1096/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 14320.4288 - acc: 0.0000e+00 - val_loss: 31432.7951 - val_acc: 0.0000e+00\n",
      "Epoch 1097/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 14024.1243 - acc: 8.7951e-04 - val_loss: 31921.4385 - val_acc: 0.0000e+00\n",
      "Epoch 1098/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 13893.3236 - acc: 0.0000e+00 - val_loss: 30679.8737 - val_acc: 0.0000e+00\n",
      "Epoch 1099/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 13216.4473 - acc: 0.0000e+00 - val_loss: 29643.5175 - val_acc: 0.0000e+00\n",
      "Epoch 1100/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 13533.9698 - acc: 0.0000e+00 - val_loss: 30158.4620 - val_acc: 0.0000e+00\n",
      "Epoch 1101/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 13752.3190 - acc: 0.0000e+00 - val_loss: 30054.4345 - val_acc: 0.0000e+00\n",
      "Epoch 1102/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13600.3926 - acc: 0.0000e+00 - val_loss: 34609.3121 - val_acc: 0.0000e+00\n",
      "Epoch 1103/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 13701.6487 - acc: 0.0000e+00 - val_loss: 31345.9773 - val_acc: 0.0000e+00\n",
      "Epoch 1104/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13396.9917 - acc: 0.0000e+00 - val_loss: 29960.8728 - val_acc: 0.0000e+00\n",
      "Epoch 1105/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 13807.7113 - acc: 0.0000e+00 - val_loss: 30890.7589 - val_acc: 0.0000e+00\n",
      "Epoch 1106/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 13694.4541 - acc: 0.0000e+00 - val_loss: 30037.0118 - val_acc: 0.0000e+00\n",
      "Epoch 1107/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 13164.4190 - acc: 0.0000e+00 - val_loss: 30284.8408 - val_acc: 0.0000e+00\n",
      "Epoch 1108/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 13678.2095 - acc: 0.0000e+00 - val_loss: 32333.7434 - val_acc: 0.0000e+00\n",
      "Epoch 1109/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 13248.0980 - acc: 0.0000e+00 - val_loss: 30051.8755 - val_acc: 0.0000e+00\n",
      "Epoch 1110/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 13866.6795 - acc: 0.0000e+00 - val_loss: 30369.2532 - val_acc: 0.0000e+00\n",
      "Epoch 1111/1200\n",
      "1137/1137 [==============================] - 0s 149us/step - loss: 14285.5814 - acc: 0.0000e+00 - val_loss: 30315.7902 - val_acc: 0.0000e+00\n",
      "Epoch 1112/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 13549.1632 - acc: 0.0000e+00 - val_loss: 31447.0264 - val_acc: 0.0000e+00\n",
      "Epoch 1113/1200\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 13427.4091 - acc: 0.0000e+00 - val_loss: 31361.3509 - val_acc: 0.0000e+00\n",
      "Epoch 1114/1200\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 13942.8208 - acc: 0.0000e+00 - val_loss: 29988.2252 - val_acc: 0.0000e+00\n",
      "Epoch 1115/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 13796.1053 - acc: 0.0000e+00 - val_loss: 30736.3897 - val_acc: 0.0000e+00\n",
      "Epoch 1116/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13495.6698 - acc: 0.0000e+00 - val_loss: 31466.3374 - val_acc: 0.0000e+00\n",
      "Epoch 1117/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 13594.1822 - acc: 0.0000e+00 - val_loss: 30878.0456 - val_acc: 0.0000e+00\n",
      "Epoch 1118/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14089.3717 - acc: 0.0000e+00 - val_loss: 30134.0809 - val_acc: 0.0000e+00\n",
      "Epoch 1119/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14150.5677 - acc: 0.0000e+00 - val_loss: 29862.3942 - val_acc: 0.0000e+00\n",
      "Epoch 1120/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 13021.9546 - acc: 0.0000e+00 - val_loss: 30151.1705 - val_acc: 0.0000e+00\n",
      "Epoch 1121/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 14117.1902 - acc: 0.0000e+00 - val_loss: 29832.1725 - val_acc: 0.0000e+00\n",
      "Epoch 1122/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 13356.4896 - acc: 0.0000e+00 - val_loss: 29805.1183 - val_acc: 0.0000e+00\n",
      "Epoch 1123/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 13319.4593 - acc: 0.0000e+00 - val_loss: 30320.5778 - val_acc: 0.0000e+00\n",
      "Epoch 1124/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 14696.5015 - acc: 0.0000e+00 - val_loss: 29856.9386 - val_acc: 0.0000e+00\n",
      "Epoch 1125/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 12815.5786 - acc: 0.0000e+00 - val_loss: 29916.4264 - val_acc: 0.0000e+00\n",
      "Epoch 1126/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 13075.3546 - acc: 0.0000e+00 - val_loss: 30895.2987 - val_acc: 0.0000e+00\n",
      "Epoch 1127/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 14396.8672 - acc: 0.0000e+00 - val_loss: 29863.9604 - val_acc: 0.0000e+00\n",
      "Epoch 1128/1200\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 13389.9736 - acc: 0.0000e+00 - val_loss: 31127.1049 - val_acc: 0.0000e+00\n",
      "Epoch 1129/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 13603.7622 - acc: 0.0000e+00 - val_loss: 30302.0407 - val_acc: 0.0000e+00\n",
      "Epoch 1130/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 13794.6822 - acc: 0.0000e+00 - val_loss: 30570.3275 - val_acc: 0.0000e+00\n",
      "Epoch 1131/1200\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 13713.6041 - acc: 0.0000e+00 - val_loss: 30127.4337 - val_acc: 0.0000e+00\n",
      "Epoch 1132/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 13388.7813 - acc: 0.0000e+00 - val_loss: 29710.9130 - val_acc: 0.0000e+00\n",
      "Epoch 1133/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 13858.8554 - acc: 0.0000e+00 - val_loss: 31031.7960 - val_acc: 0.0000e+00\n",
      "Epoch 1134/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 13894.1879 - acc: 0.0000e+00 - val_loss: 32192.8436 - val_acc: 0.0000e+00\n",
      "Epoch 1135/1200\n",
      "1137/1137 [==============================] - 0s 168us/step - loss: 13498.3158 - acc: 0.0000e+00 - val_loss: 30521.3111 - val_acc: 0.0000e+00\n",
      "Epoch 1136/1200\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 13321.0933 - acc: 0.0000e+00 - val_loss: 29971.7554 - val_acc: 0.0000e+00\n",
      "Epoch 1137/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 13456.0785 - acc: 0.0000e+00 - val_loss: 31183.8305 - val_acc: 0.0000e+00\n",
      "Epoch 1138/1200\n",
      "1137/1137 [==============================] - 0s 148us/step - loss: 13066.5608 - acc: 0.0000e+00 - val_loss: 30885.2417 - val_acc: 0.0000e+00\n",
      "Epoch 1139/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13346.7385 - acc: 8.7951e-04 - val_loss: 30875.2706 - val_acc: 0.0000e+00\n",
      "Epoch 1140/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 14055.6600 - acc: 0.0000e+00 - val_loss: 30895.4525 - val_acc: 0.0000e+00\n",
      "Epoch 1141/1200\n",
      "1137/1137 [==============================] - 0s 165us/step - loss: 14685.9483 - acc: 0.0000e+00 - val_loss: 31837.0379 - val_acc: 0.0000e+00\n",
      "Epoch 1142/1200\n",
      "1137/1137 [==============================] - 0s 208us/step - loss: 13245.7446 - acc: 0.0000e+00 - val_loss: 30579.2622 - val_acc: 0.0000e+00\n",
      "Epoch 1143/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 13694.6798 - acc: 0.0000e+00 - val_loss: 29681.6586 - val_acc: 0.0000e+00\n",
      "Epoch 1144/1200\n",
      "1137/1137 [==============================] - 0s 175us/step - loss: 13425.4274 - acc: 0.0000e+00 - val_loss: 30612.8726 - val_acc: 0.0000e+00\n",
      "Epoch 1145/1200\n",
      "1137/1137 [==============================] - 0s 183us/step - loss: 13414.5157 - acc: 0.0000e+00 - val_loss: 30849.4924 - val_acc: 0.0000e+00\n",
      "Epoch 1146/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 173us/step - loss: 13705.2566 - acc: 0.0000e+00 - val_loss: 31739.6230 - val_acc: 0.0000e+00\n",
      "Epoch 1147/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 13421.1346 - acc: 0.0000e+00 - val_loss: 31140.0016 - val_acc: 0.0000e+00\n",
      "Epoch 1148/1200\n",
      "1137/1137 [==============================] - 0s 170us/step - loss: 14258.6517 - acc: 0.0000e+00 - val_loss: 30108.4142 - val_acc: 0.0000e+00\n",
      "Epoch 1149/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14110.8932 - acc: 0.0000e+00 - val_loss: 32166.3882 - val_acc: 0.0000e+00\n",
      "Epoch 1150/1200\n",
      "1137/1137 [==============================] - 0s 151us/step - loss: 13461.7789 - acc: 0.0000e+00 - val_loss: 31005.3794 - val_acc: 0.0000e+00\n",
      "Epoch 1151/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 13936.9650 - acc: 8.7951e-04 - val_loss: 30517.8819 - val_acc: 0.0000e+00\n",
      "Epoch 1152/1200\n",
      "1137/1137 [==============================] - 0s 176us/step - loss: 14480.6042 - acc: 0.0000e+00 - val_loss: 32971.7687 - val_acc: 0.0000e+00\n",
      "Epoch 1153/1200\n",
      "1137/1137 [==============================] - 0s 179us/step - loss: 14574.9521 - acc: 0.0000e+00 - val_loss: 30612.7741 - val_acc: 0.0000e+00\n",
      "Epoch 1154/1200\n",
      "1137/1137 [==============================] - 0s 178us/step - loss: 13565.0906 - acc: 0.0000e+00 - val_loss: 32113.3068 - val_acc: 0.0000e+00\n",
      "Epoch 1155/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 14139.8885 - acc: 0.0000e+00 - val_loss: 31400.5981 - val_acc: 0.0000e+00\n",
      "Epoch 1156/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 12734.5927 - acc: 0.0000e+00 - val_loss: 30711.7538 - val_acc: 0.0000e+00\n",
      "Epoch 1157/1200\n",
      "1137/1137 [==============================] - 0s 170us/step - loss: 13350.7289 - acc: 0.0000e+00 - val_loss: 31265.5805 - val_acc: 0.0000e+00\n",
      "Epoch 1158/1200\n",
      "1137/1137 [==============================] - 0s 170us/step - loss: 13713.3867 - acc: 0.0000e+00 - val_loss: 30812.9924 - val_acc: 0.0000e+00\n",
      "Epoch 1159/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 13466.1235 - acc: 0.0000e+00 - val_loss: 35259.2474 - val_acc: 0.0000e+00\n",
      "Epoch 1160/1200\n",
      "1137/1137 [==============================] - 0s 175us/step - loss: 14850.6320 - acc: 0.0000e+00 - val_loss: 31009.3356 - val_acc: 0.0000e+00\n",
      "Epoch 1161/1200\n",
      "1137/1137 [==============================] - 0s 190us/step - loss: 13315.9813 - acc: 0.0000e+00 - val_loss: 32569.4170 - val_acc: 0.0000e+00\n",
      "Epoch 1162/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 13736.3024 - acc: 0.0000e+00 - val_loss: 31624.9178 - val_acc: 0.0000e+00\n",
      "Epoch 1163/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 12920.4093 - acc: 8.7951e-04 - val_loss: 30717.6067 - val_acc: 0.0000e+00\n",
      "Epoch 1164/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 13369.3819 - acc: 0.0000e+00 - val_loss: 31534.0304 - val_acc: 0.0000e+00\n",
      "Epoch 1165/1200\n",
      "1137/1137 [==============================] - 0s 176us/step - loss: 13673.8622 - acc: 0.0000e+00 - val_loss: 30804.1115 - val_acc: 0.0000e+00\n",
      "Epoch 1166/1200\n",
      "1137/1137 [==============================] - 0s 195us/step - loss: 12875.8624 - acc: 0.0000e+00 - val_loss: 31926.7784 - val_acc: 0.0000e+00\n",
      "Epoch 1167/1200\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 13997.1042 - acc: 0.0000e+0 - 0s 177us/step - loss: 13640.9490 - acc: 0.0000e+00 - val_loss: 31657.6016 - val_acc: 0.0000e+00\n",
      "Epoch 1168/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 13377.2175 - acc: 0.0000e+00 - val_loss: 31372.0831 - val_acc: 0.0000e+00\n",
      "Epoch 1169/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 13288.7648 - acc: 0.0000e+00 - val_loss: 30040.5430 - val_acc: 0.0000e+00\n",
      "Epoch 1170/1200\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 14069.0430 - acc: 0.0000e+00 - val_loss: 30489.8927 - val_acc: 0.0000e+00\n",
      "Epoch 1171/1200\n",
      "1137/1137 [==============================] - 0s 178us/step - loss: 13203.0634 - acc: 0.0000e+00 - val_loss: 31286.2867 - val_acc: 0.0000e+00\n",
      "Epoch 1172/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 13283.7644 - acc: 0.0000e+00 - val_loss: 29420.2057 - val_acc: 0.0000e+00\n",
      "Epoch 1173/1200\n",
      "1137/1137 [==============================] - 0s 172us/step - loss: 13565.7566 - acc: 0.0000e+00 - val_loss: 30362.9595 - val_acc: 0.0000e+00\n",
      "Epoch 1174/1200\n",
      "1137/1137 [==============================] - 0s 161us/step - loss: 13280.2939 - acc: 0.0000e+00 - val_loss: 31763.7207 - val_acc: 0.0000e+00\n",
      "Epoch 1175/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 12701.8450 - acc: 0.0000e+00 - val_loss: 30924.5108 - val_acc: 0.0000e+00\n",
      "Epoch 1176/1200\n",
      "1137/1137 [==============================] - 0s 153us/step - loss: 12781.7873 - acc: 0.0000e+00 - val_loss: 30829.8944 - val_acc: 0.0000e+00\n",
      "Epoch 1177/1200\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 12870.2984 - acc: 0.0000e+00 - val_loss: 30294.7199 - val_acc: 0.0000e+00\n",
      "Epoch 1178/1200\n",
      "1137/1137 [==============================] - 0s 180us/step - loss: 13300.9167 - acc: 0.0000e+00 - val_loss: 29739.4501 - val_acc: 0.0000e+00\n",
      "Epoch 1179/1200\n",
      "1137/1137 [==============================] - 0s 163us/step - loss: 13260.6559 - acc: 0.0000e+00 - val_loss: 30894.7228 - val_acc: 0.0000e+00\n",
      "Epoch 1180/1200\n",
      "1137/1137 [==============================] - 0s 183us/step - loss: 13151.7242 - acc: 0.0000e+00 - val_loss: 30081.6563 - val_acc: 0.0000e+00\n",
      "Epoch 1181/1200\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 13044.4325 - acc: 0.0000e+00 - val_loss: 31520.4568 - val_acc: 0.0000e+00\n",
      "Epoch 1182/1200\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 13691.0058 - acc: 0.0000e+00 - val_loss: 30951.8105 - val_acc: 0.0000e+00\n",
      "Epoch 1183/1200\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 14013.7463 - acc: 0.0000e+00 - val_loss: 30934.8089 - val_acc: 0.0000e+00\n",
      "Epoch 1184/1200\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 15005.8315 - acc: 0.0000e+00 - val_loss: 30954.8727 - val_acc: 0.0000e+00\n",
      "Epoch 1185/1200\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 13447.1418 - acc: 0.0000e+00 - val_loss: 30601.0394 - val_acc: 0.0000e+00\n",
      "Epoch 1186/1200\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 14151.0260 - acc: 0.0000e+00 - val_loss: 31162.4742 - val_acc: 0.0000e+00\n",
      "Epoch 1187/1200\n",
      "1137/1137 [==============================] - 0s 147us/step - loss: 13107.1643 - acc: 0.0000e+00 - val_loss: 31389.7146 - val_acc: 0.0000e+00\n",
      "Epoch 1188/1200\n",
      "1137/1137 [==============================] - 0s 152us/step - loss: 13407.4423 - acc: 8.7951e-04 - val_loss: 32030.9200 - val_acc: 0.0000e+00\n",
      "Epoch 1189/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 14129.6421 - acc: 0.0000e+00 - val_loss: 32437.4287 - val_acc: 0.0000e+00\n",
      "Epoch 1190/1200\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 13830.7088 - acc: 0.0000e+00 - val_loss: 30326.4620 - val_acc: 0.0000e+00\n",
      "Epoch 1191/1200\n",
      "1137/1137 [==============================] - 0s 171us/step - loss: 12818.4825 - acc: 0.0000e+00 - val_loss: 30570.2723 - val_acc: 0.0000e+00\n",
      "Epoch 1192/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 13136.7758 - acc: 0.0000e+00 - val_loss: 31473.5265 - val_acc: 0.0000e+00\n",
      "Epoch 1193/1200\n",
      "1137/1137 [==============================] - 0s 144us/step - loss: 13190.6689 - acc: 0.0000e+00 - val_loss: 31938.0128 - val_acc: 0.0000e+00\n",
      "Epoch 1194/1200\n",
      "1137/1137 [==============================] - 0s 159us/step - loss: 14207.0941 - acc: 0.0000e+00 - val_loss: 31646.1632 - val_acc: 0.0000e+00\n",
      "Epoch 1195/1200\n",
      "1137/1137 [==============================] - 0s 150us/step - loss: 13666.5721 - acc: 0.0000e+00 - val_loss: 33879.3305 - val_acc: 0.0000e+00\n",
      "Epoch 1196/1200\n",
      "1137/1137 [==============================] - 0s 158us/step - loss: 13396.6371 - acc: 0.0000e+00 - val_loss: 32335.6750 - val_acc: 0.0000e+00\n",
      "Epoch 1197/1200\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 13302.4510 - acc: 0.0000e+00 - val_loss: 29971.7493 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1198/1200\n",
      "1137/1137 [==============================] - 0s 160us/step - loss: 12845.8738 - acc: 0.0000e+00 - val_loss: 31070.4603 - val_acc: 0.0000e+00\n",
      "Epoch 1199/1200\n",
      "1137/1137 [==============================] - 0s 154us/step - loss: 13496.2261 - acc: 0.0000e+00 - val_loss: 31796.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1200/1200\n",
      "1137/1137 [==============================] - 0s 156us/step - loss: 13657.7408 - acc: 0.0000e+00 - val_loss: 32093.8847 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 175))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 40, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 30, init = 'he_uniform',activation='relu'))\n",
    "classifier.add(Dense(output_dim = 20, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax',metrics=['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(x_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# regressor = RandomForestRegressor(n_estimators = 10,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission9.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
